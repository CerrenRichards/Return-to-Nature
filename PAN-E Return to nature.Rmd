---
title: "PAN-E Return to nature"
author: "Cerren Richards"
date: "14/05/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Here we use the Google mobility data to explore the response of people returning to nature after COVID-19 confinements.

#_______________________

### Google Data

**Data Description**:

* How visits and length of stay at different places change compared to a baseline.
    - Parks: national parks, public beaches, marinas, dog parks, plazas, and public gardens.
    - Residential: places of residence
    - Grocery & Pharmacy: grocery markets, food warehouses, farmers markets, 
                          specialty food shops, drug stores, and pharmacies.
    - Retail & Recreation:restaurants, cafes, shopping centers, theme parks,
                          museums, libraries, and movie theaters
    
* Baseline: Median value, for the corresponding day of the week, during the 5- week period Jan 3–Feb 6, 2020

**Download data and methods**:

* https://www.google.com/covid19/mobility/
* https://support.google.com/covid19-mobility/answer/9824897?hl=en&ref_topic=9822927
* https://www.google.com/covid19/mobility/data_documentation.html?hl=en


#_______________________

#######################
## SIMPLIFIED METHODS
#######################

## Download the Google mobility data

In this chunk we download the Google mobility data, reorganise it and select only the overall country trends. 

```{r, error=FALSE, warning=FALSE}

# These data were downloaded in October 2020
google <- readRDS(file = "Global_Mobility_Report.rds")

# R reads Namibia's iso2 code is as an "is.na" object, so we will rename it to NA
google$country_region_code[is.na(google$country_region_code)] <-"NA"

library(countrycode)

# Add the country codes so we ensure everything matches 
google$ISO2 <- google$country_region_code
google$ISO3 <- countrycode(google$ISO2, origin = 'iso2c', destination = 'iso3c')
google$country <- countrycode(google$ISO2, origin = 'iso2c', destination = 'country.name')

# Add Julian date
google$julian<- (strptime(google$date, "%Y-%m-%d")$yday) + 1 # need to add 1 day because 2020 is a leap year

library(naniar)

# remove the subregions and only keep the overall country pattern
google <- google %>% replace_with_na(replace = list(sub_region_1 = ""))
google <- google[is.na(google$sub_region_1),]

library(dplyr)

# Select the specific data and rename columns
google_countries <- google %>% select(country, ISO3, date,  julian,
                    `Parks & Beaches`= 
                     parks_percent_change_from_baseline,
                    `Grocery & Pharmacy` = 
                     grocery_and_pharmacy_percent_change_from_baseline,
                     Residential = 
                     residential_percent_change_from_baseline,
                    `Retail & Recreation` = 
                      retail_and_recreation_percent_change_from_baseline) 

```


# Plot the regional trends for parks, pharmacies and residential

Here we extract the continent and regional information for each of the countries, reorganise the data and plot the trends in change of time spent at parks, pharmacies and residential during lockdown in Africa, Americas, Asia, Europe and Oceania.


```{r}
# Load packages
library(ggplot2);library(viridis); library(ggpubr);library(sf);library("rnaturalearth"); library("rnaturalearthdata"); library(tidyr)


# extract continent info
# These data will be used to match the world regions to the google data
world <- ne_countries(scale = "medium", returnclass = "sf")
world <- world %>% rename(ISO3 = iso_a3) 
region_un <- world$region_un
continent <- world$continent
ISO3 <- world$ISO3
continent<- tibble(ISO3, region_un, continent)


# join the regional data to the google data
google_countries <- left_join(google_countries, continent, by = "ISO3")

# assign Tuvalu to Oceania
google_countries$region_un[is.na(google_countries$region_un)] <-"Oceania"

## Define "date" as a date 
google_countries$date <- as.Date(google_countries$date)

## Rearrange for plotting
google_countries <- google_countries %>% gather(type, change, 
                                                `Parks & Beaches`:`Retail & Recreation`)


## Calculate regional median movement at parks, pharmacies and residential
google_median_regional <- google_countries %>% group_by(date, type, region_un) %>% 
      summarise(change = median(change, na.rm = TRUE))


## Create plot theme
regional_plottheme <-  theme_bw(base_size = 15)+ # set the background theme   
   theme(panel.grid.major = element_blank(), # remove the major lines
        panel.grid.minor = element_blank(), # remove the minor lines
        #axis.text.x = element_text(angle = 90), # rotate the x-axis text
        axis.title.x = element_blank(),
        strip.text.x = element_text(size = 15, color = "white"), 
        strip.background = element_rect(fill="black")) # remove x-axis title


## Explore the regional trends
# Parks and Beaches
ggplot() +
  geom_line(data = filter(google_countries, type == "Parks & Beaches"),
            aes(date, change, group = country_region),
            colour = alpha("grey", 0.5))+
  geom_line(data = filter(google_median_regional, type == "Parks & Beaches"),
            aes(date, change))+
  geom_hline(yintercept = 0, linetype = "dashed")+
  scale_x_date(date_breaks = "8 week", date_labels = "%b %d")+
  facet_wrap(~region_un, scales = "free", ncol = 3)+
  labs(y = "Change in length of visit (%)",
       title = "Parks & Beaches")+
  regional_plottheme



# Grocery & Pharmacy
ggplot() +
  geom_line(data = filter(google_countries, type == "Grocery & Pharmacy"),
            aes(date, change, group = country_region),
            colour = alpha("grey", 0.5))+
    geom_line(data = filter(google_median_regional, type == "Grocery & Pharmacy"),
            aes(date, change))+
  geom_hline(yintercept = 0, linetype = "dashed")+
  scale_x_date(date_breaks = "8 week", date_labels = "%b %d")+
  facet_wrap(~region_un, scales = "free", ncol = 3)+
  labs(y = "Change in length of visit (%)",
       title = "Grocery & Pharmacy")+
  regional_plottheme


# Residential
ggplot() +
  geom_line(data = filter(google_countries, type == "Residential"),
            aes(date, change, group = country_region),
            colour = alpha("grey", 0.5))+
  geom_line(data = filter(google_median_regional, type == "Residential"),
            aes(date, change))+
  geom_hline(yintercept = 0, linetype = "dashed")+
  scale_x_date(date_breaks = "8 week", date_labels = "%b %d")+
  facet_wrap(~region_un, scales = "free", ncol = 3)+
  labs(y = "Change in length of visit (%)",
       title = "Residential")+
  regional_plottheme

```


## Global plot for time at parks, pharmacies and residential

Here we calculate and plot the global median change of time at parks, pharmacies and residential during lockdown.

At the global scale, people returned to nature five days before (parks & beaches: 19-08-2020) they returned to get basic human needs (grocery & pharmacy: 24-08-2020), and 15 days before they returned to retail and recreation stores (03-09-2020). Date represents the day that the global median crossed zero.

```{r}

library(dplyr); library(tidyr)

## Calculate global median movement at parks, pharmacies and residential
google_median <- google %>% group_by(date) %>% 
      summarise(`Parks & Beaches`= 
                 median(parks_percent_change_from_baseline, na.rm = TRUE),
                `Grocery & Pharmacy` = 
                 median(grocery_and_pharmacy_percent_change_from_baseline, na.rm = TRUE),
                 Residential = 
                 median(residential_percent_change_from_baseline, na.rm = TRUE),
                `Retail & Recreation` = 
                  median(retail_and_recreation_percent_change_from_baseline, na.rm = TRUE))

## Define "date" as a date 
google_median$date <- as.Date(google_median$date)

## Rearrange for plotting
google_median <- google_median %>% gather(type, change, `Parks & Beaches`:`Retail & Recreation`)

## Define plot theme
global_plottheme <- theme_bw(base_size = 15)+ # set the background theme       
  theme(panel.grid.major = element_blank(), # remove the major lines
        panel.grid.minor = element_blank(), # remove the minor lines
        axis.title.x = element_blank(),
        strip.text.x = element_text(size = 15, color = "white"), 
        strip.background = element_rect(fill="black"))


## Create global plot
ggplot(google_median, aes(date, change)) +
  geom_line(data = google_countries, 
            aes(group = country_region), 
            colour = alpha("grey", 0.5))+
  geom_line(size = 1)+
  geom_vline(xintercept = as.numeric(as.Date("2020-07-28")), 
             linetype = "dashed", colour = "red", size = 1)+
  geom_hline(yintercept = 0, linetype = "dashed")+
  scale_x_date(date_breaks = "8 week", date_labels = "%b %d")+
  facet_wrap(~type, scales = "free", nrow = 2)+
  labs(y = "Change in length of visit (%)")+
  global_plottheme


# Save the plot
ggsave("Parks_grocery_residential.pdf", 
       dpi = 600, 
       width = 160, height = 200, unit = "mm")
```


#######################
## ADVANCED METHODS
#######################

1. Use GAM models to identify the anthropause date for each country based on the greatest change of people being confined to their homes (same approach as BIOC paper)

2. Find the date that each country's mobility crosses zero (e.g., "returns" to nature, necessities, luxuries)

3. Calculate the number of days between the lockdown date and the return date for each country

4. Calculate the average global and continental return days for nature, necessities, luxuries

5. Compare whether there is a global and continental difference between the return days to nature, necessities, luxuries


## Download the Google mobility data

In this chunk we download the Google mobility data, reorganise it and select only the overall country trends. 

```{r, error=FALSE, warning=FALSE}

# These data were downloaded in October 2020
google <- readRDS(file = "Global_Mobility_Report.rds")

# These data were downloaded in September 2022
google <- read.csv("Global_Mobility_Report_latest.csv")

# Filter for only 2020 data
google$date2 <- as.Date(google$date)
google <- google %>% filter(date2 <= "2020-12-31")

# R reads Namibia's iso2 code is as an "is.na" object, so we will rename it to NA
google$country_region_code[is.na(google$country_region_code)] <-"NA"

library(countrycode)

# Add the country codes so we ensure everything matches 
google$ISO2 <- google$country_region_code
google$ISO3 <- countrycode(google$ISO2, origin = 'iso2c', destination = 'iso3c')
google$country <- countrycode(google$ISO2, origin = 'iso2c', destination = 'country.name')

# Add Julian date
google$julian<- (strptime(google$date, "%Y-%m-%d")$yday) + 1 # need to add 1 day because 2020 is a leap year

library(naniar)

# remove the subregions and metro areas and only keep the overall country pattern
google <- google %>% filter(metro_area == "" & sub_region_1 == "")

library(dplyr)

# Select the specific data and rename columns
google_countries <- google %>% select(country, ISO3, date,  julian,
                    `Parks & Beaches`= 
                     parks_percent_change_from_baseline,
                    `Grocery & Pharmacy` = 
                     grocery_and_pharmacy_percent_change_from_baseline,
                     Residential = 
                     residential_percent_change_from_baseline,
                    `Retail & Recreation` = 
                      retail_and_recreation_percent_change_from_baseline) 

```


### COVID-19 Confinement Data

The Oxford Covid-19 Government Response Tracker (OxCGRT) has compiled dates for eight different confinement types and their severity (0-4).

Data info: https://github.com/OxCGRT/covid-policy-tracker

The data are constantly being updated, therefore the link may change in the future.

```{r, eval=FALSE}
library(RCurl)

# Call the OxCGRT data from GitHub
confinement <- getURL("https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker-legacy/main/legacy_data_202207/OxCGRT_latest.csv")


# Set up the confinement data for further analyses
conf <- read.csv(text=confinement) %>% 
  mutate(julian=(strptime(Date, "%Y%m%d")$yday)+1) %>% # assign Julian Date
  mutate(Date=as.Date(strptime(Date, "%Y%m%d"))) %>% # Set as a date 
  mutate(weekday=weekdays(Date)) %>% # Identify weekdays
  mutate(weekend=ifelse(grepl("Sat|Sun", weekday), 1,0)) %>% # Assign columns for weekends
  select(ISO3=CountryCode, RegionName, Date, julian, weekday, weekend, # Select columns
         C1_School.closing, C2_Workplace.closing, C3_Cancel.public.events,
         C4_Restrictions.on.gatherings, C5_Close.public.transport,
         C6_Stay.at.home.requirements, C7_Restrictions.on.internal.movement) %>%
  filter(Date <="2020-09-11")

# Remove subregions
conf<- conf %>% replace_with_na(replace = list(RegionName = ""))
conf<- conf[is.na(conf$RegionName),]

```


### SENSITIVITY ANALYSIS and Extract t-statistic for each country

We divided each country’s mobility data into ‘before’ and ‘after’ periods for each confinement type and level, ran generalised additive models to determine which division best characterised the observed changes in mobility patterns. 

```{r, eval = FALSE}

# Sensitivity analysis to identify the best cut off dates
# We select May because this is when most countries begin to ease the restrictions
maystart <- 122 # Julian date for May 1st
maymid <- 136 # May 15
mayend <- 152 # May 30

# Subset the google data
googlestart <- subset(google_countries,  julian <= maystart)
googlemid <- subset(google_countries,  julian <= maymid)
googleend <- subset(google_countries,  julian <= mayend)

# Join the Google data with the confinement data
googlestart <- left_join(googlestart, conf, by = c("ISO3", "julian"))
googlemid <- left_join(googlemid, conf, by = c("ISO3", "julian"))
googleend <- left_join(googleend, conf, by = c("ISO3", "julian"))


# List seven of the confinement types 
conftypes=c("C1_School.closing", "C2_Workplace.closing", "C3_Cancel.public.events",
            "C4_Restrictions.on.gatherings", "C5_Close.public.transport",
            "C6_Stay.at.home.requirements", "C7_Restrictions.on.internal.movement")

###_________________________________________
### MID MAY
###_________________________________________

# Create empty spaces for results to be pasted
country=ISO3=restriction=level=date=character() # set as character
aics=R2=t.lockdown=pval=numeric() # set as numeric

# Create empty dataframes and lists for model outputs
country.results=subdat.list=chosen_mid=data.frame()
mod.list=country.results=list()

library(mgcv)
library(lubridate)

# Run loop to extract the t-statistic
for(i in unique(googlemid$country)){
  for(j in conftypes){
    subdat=subset(googlemid, country==i)  
    locklevels=unique(subdat[[j]])
    locklevels=locklevels[which(locklevels %in% c(1:10))]
    for(k in locklevels){
      subdat$lockdown=(subdat[[j]]==k)*1
      subdat$lockdown.type=j
      subdat$level=k
      mod=try(gam(Residential ~ lockdown + weekend + s(julian), data=subdat))
      if(!class(mod)[1]=="try-error"){
        country=c(country,i)
        ISO3=c(ISO3, subdat$ISO3[1])
        restriction=c(restriction,j)
        level=c(level,k)
        aics=c(aics,AIC(mod))
        R2=c(R2, summary(mod)$r.sq)
        t.lockdown=c(t.lockdown, summary(mod)$p.table["lockdown","t value"])
        pval=c(pval, summary(mod)$p.table["lockdown","Pr(>|t|)"])
        date=c(date, subdat$date[min(which(subdat$lockdown==1))])
      

        # save models and subdata
        mod.list[[paste(i,j,k, sep="_")]]=mod
        subdat.list=rbind(subdat.list, subset(subdat, 
                                              select=c("country", "date", "julian", "weekday",
                                                       "lockdown.type","level",  "Residential",
                                                        "lockdown")))
        
      }
    }
  }
  
  # select country top model
  country.out=data.frame(country, ISO3, restriction, level, aics, R2, t.lockdown, pval, date) %>%
    mutate(Date=ymd(date)) %>%
    subset(country==i) %>% 
    arrange(aics)
  
  country.results=rbind(country.results,country.out)
  
  country.out=subset(country.out, t.lockdown==max(t.lockdown))
  country.out$model = with(country.out, paste(country, restriction, level, sep="_"))
  
  # add top model outputs to list
  chosen_mid=rbind(chosen_mid,country.out)
  
  print(paste(i))
}

# Assign Julian date for the confinement date
chosen_mid$julian_lockdown <- (strptime(chosen_mid$date, "%Y-%m-%d")$yday) + 1 

chosen_mid<- distinct(chosen_mid, country, .keep_all = TRUE)

# Find median AIC score for all countries
median(chosen_mid$aics) #466

###_________________________________________
### END MAY
###_________________________________________


# Create empty spaces for results to be pasted
country=ISO3=restriction=level=date=character() # set as character
aics=R2=t.lockdown=pval=numeric() # set as numeric

# Create empty dataframes and lists for model outputs
country.results=subdat.list=chosen_end=data.frame()
mod.list=country.results=list()


# Run loop to extract the t-statistic
for(i in unique(googleend$country)){
  for(j in conftypes){
    subdat=subset(googleend, country==i)  
    locklevels=unique(subdat[[j]])
    locklevels=locklevels[which(locklevels %in% c(1:10))]
    for(k in locklevels){
      subdat$lockdown=(subdat[[j]]==k)*1
      subdat$lockdown.type=j
      subdat$level=k
      mod=try(gam(Residential ~ lockdown + weekend + s(julian), data=subdat))
      if(!class(mod)[1]=="try-error"){
        country=c(country,i)
        ISO3=c(ISO3, subdat$ISO3[1])
        restriction=c(restriction,j)
        level=c(level,k)
        aics=c(aics,AIC(mod))
        R2=c(R2, summary(mod)$r.sq)
        t.lockdown=c(t.lockdown, summary(mod)$p.table["lockdown","t value"])
        pval=c(pval, summary(mod)$p.table["lockdown","Pr(>|t|)"])
        date=c(date, subdat$date[min(which(subdat$lockdown==1))])
      

        # save models and subdata
        mod.list[[paste(i,j,k, sep="_")]]=mod
        subdat.list=rbind(subdat.list, subset(subdat, 
                                              select=c("country", "date", "julian", "weekday",
                                                       "lockdown.type","level",  "Residential",
                                                        "lockdown")))
        
      }
    }
  }
  
  # select country top model
  country.out=data.frame(country, ISO3, restriction, level, aics, R2, t.lockdown, pval, date) %>%
    mutate(Date=ymd(date)) %>%
    subset(country==i) %>% 
    arrange(aics)
  
  country.results=rbind(country.results,country.out)
  
  country.out=subset(country.out, t.lockdown==max(t.lockdown))
  country.out$model = with(country.out, paste(country, restriction, level, sep="_"))
  
  # add top model outputs to list
  chosen_end=rbind(chosen_end,country.out)
  
  print(paste(i))
}

# Assign Julian date for the confinement date
chosen_end$julian_lockdown <- (strptime(chosen_end$date, "%Y-%m-%d")$yday) + 1 


chosen_end<- distinct(chosen_end, country, .keep_all = TRUE)

# Find median AIC score for all countries
median(chosen_end$aics) #543


###_________________________________________
### START MAY
###_________________________________________

# Create empty spaces for results to be pasted
country=ISO3=restriction=level=date=character() # set as character
aics=R2=t.lockdown=pval=numeric() # set as numeric

# Create empty dataframes and lists for model outputs
country.results=subdat.list=chosen_start=data.frame()
mod.list=country.results=list()

# Run loop to extract the t-statistic
for(i in unique(googlestart$country)){
  for(j in conftypes){
    subdat=subset(googlestart, country==i)  
    locklevels=unique(subdat[[j]])
    locklevels=locklevels[which(locklevels %in% c(1:10))]
    for(k in locklevels){
      subdat$lockdown=(subdat[[j]]==k)*1
      subdat$lockdown.type=j
      subdat$level=k
      mod=try(gam(Residential ~ lockdown + weekend + s(julian), data=subdat))
      if(!class(mod)[1]=="try-error"){
        country=c(country,i)
        ISO3=c(ISO3, subdat$ISO3[1])
        restriction=c(restriction,j)
        level=c(level,k)
        aics=c(aics,AIC(mod))
        R2=c(R2, summary(mod)$r.sq)
        t.lockdown=c(t.lockdown, summary(mod)$p.table["lockdown","t value"])
        pval=c(pval, summary(mod)$p.table["lockdown","Pr(>|t|)"])
        date=c(date, subdat$date[min(which(subdat$lockdown==1))])
      

        # save models and subdata
        mod.list[[paste(i,j,k, sep="_")]]=mod
        subdat.list=rbind(subdat.list, subset(subdat, 
                                              select=c("country", "date", "julian", "weekday",
                                                       "lockdown.type","level",  "Residential",
                                                        "lockdown")))
        
      }
    }
  }
  
  # select country top model
  country.out=data.frame(country, ISO3, restriction, level, aics, R2, t.lockdown, pval, date) %>%
    mutate(date=ymd(date)) %>%
    subset(country==i) %>% 
    arrange(aics)
  
  country.results=rbind(country.results,country.out)
  
  country.out=subset(country.out, t.lockdown==max(t.lockdown))
  country.out$model = with(country.out, paste(country, restriction, level, sep="_"))
  
  # add top model outputs to list
  chosen_start=rbind(chosen_start,country.out)
  
  print(paste(i))
}

# Assign Julian date for the confinement date
chosen_start$julian_lockdown <- (strptime(chosen_start$date, "%Y-%m-%d")$yday) + 1 

# Remove duplicated countries (that have the same AIC score for multiple confinement types)
chosen_start<- distinct(chosen_start, country, .keep_all = TRUE)

# Find median AIC score for all countries
median(chosen_start$aics) #393


```



### Plot the individual country trends with lockdown date

```{r, eval = FALSE}

# Join the lockdown dates to the full Google data for plotting
googleplots <- left_join(googlestart, chosen_start, by = c("country", "ISO3"))

library(ggplot2)
library(ggforce)
## PLOT
ggplot(data = googleplots, aes(x=julian, y=Residential)) + 
  geom_line() + 
  facet_wrap_paginate(~country, ncol = 7, nrow = 7, scale="free_y", page = 1)+
  geom_vline(aes(xintercept = julian_lockdown), colour = "red")

ggplot(data = googleplots, aes(x=julian, y=Residential)) + 
  geom_line() + 
  facet_wrap_paginate(~country, ncol = 7, nrow = 7, scale="free_y", page = 2)+
  geom_vline(aes(xintercept = julian_lockdown), colour = "red")

ggplot(data = googleplots, aes(x=julian, y=Residential)) + 
  geom_line() + 
  facet_wrap_paginate(~country, ncol = 7, nrow = 7, scale="free_y", page = 3)+
  geom_vline(aes(xintercept = julian_lockdown), colour = "red")


```





# Add the continental info to the google data

```{r}
# Load packages
library(ggplot2);library(viridis); library(ggpubr);library(sf);library("rnaturalearth"); library("rnaturalearthdata"); library(tidyr)


# extract continent info
# These data will be used to match the world regions to the google data
world <- ne_countries(scale = "medium", returnclass = "sf")
world <- world %>% rename(ISO3 = iso_a3) 
region_un <- world$region_un
continent <- world$continent
ISO3 <- world$ISO3
continent<- tibble(ISO3, region_un, continent)


# join the regional data to the google data
google_countries <- left_join(google_countries, continent, by = "ISO3")

# assign Tuvalu to Oceania
google_countries$region_un[is.na(google_countries$region_un)] <-"Oceania"

## Define "date" as a date 
google_countries$date <- as.Date(google_countries$date)

```



## Date countries cross zero

```{r}

## Join the lockdown date to the google data
google2 <- left_join(google, 
                     chosen_start %>% select(country, ISO3, julian_lockdown))


## Identify the day that a country's mobility crosses zero
## and calculate the number of days after lockdown that the 
## country's mobility crossed zero
google2 %>% group_by(country, ISO3) %>% 
            filter(julian > julian_lockdown & parks > 0) %>%
            summarise(lockdown = min(julian_lockdown),
                      parks_zero = min(julian),
                      parks_diff = parks_zero - lockdown)





```



# Exploring changepoint

```{r}

cameroon <- google_countries %>% filter(country == "Cameroon")
brazil <- google_countries %>% filter(country == "Brazil")
estonia <- google_countries %>% filter(country == "Estonia" & julian < 122) 

library(changepoint)
cpt1 <- cpts(cpt.meanvar(estonia$Residential, method = "BinSeg", Q=1))

ggplot(data = estonia, aes(x=julian, y=Residential)) + 
  geom_line() + 
  geom_vline(aes(xintercept = 75), colour = "red")

```


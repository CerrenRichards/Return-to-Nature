---
title: "PAN-E Return to nature"
author: "Cerren Richards"
date: "14/05/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Here we use the Google mobility data to explore the response of people returning to nature after COVID-19 confinements.

#_______________________

### Google Data

**Data Description**:

* How visits and length of stay at different places change compared to a baseline.
    - Parks: national parks, public beaches, marinas, dog parks, plazas, and public gardens.
    - Residential: places of residence
    - Grocery & Pharmacy: grocery markets, food warehouses, farmers markets, 
                          specialty food shops, drug stores, and pharmacies.
    
* Baseline: Median value, for the corresponding day of the week, during the 5- week period Jan 3â€“Feb 6, 2020

**Download data and methods**:

* https://www.google.com/covid19/mobility/
* https://support.google.com/covid19-mobility/answer/9824897?hl=en&ref_topic=9822927

#_______________________

#######################
## SIMPLIFIED METHODS
#######################

## Download the Google mobility data

In this chunk we download the Google mobility data, reorganise it and select only the overall country trends. 

```{r, error=FALSE, warning=FALSE}

# These data were downloaded in October 2020
google <- readRDS(file = "Global_Mobility_Report.rds")

# R reads Namibia's iso2 code is as an "is.na" object, so we will rename it to NA
google$country_region_code[is.na(google$country_region_code)] <-"NA"

library(countrycode)

# Add the country codes so we ensure everything matches 
google$ISO2 <- google$country_region_code
google$ISO3 <- countrycode(google$ISO2, origin = 'iso2c', destination = 'iso3c')
google$country <- countrycode(google$ISO2, origin = 'iso2c', destination = 'country.name')

# Add Julian date
google$julian<- (strptime(google$date, "%Y-%m-%d")$yday) + 1 # need to add 1 day because 2020 is a leap year

library(naniar)

# remove the subregions and only keep the overall country pattern
google <- google %>% replace_with_na(replace = list(sub_region_1 = ""))
google <- google[is.na(google$sub_region_1),]

library(dplyr)

# Select the specific data and rename columns
google_countries <- google %>% select(date,country_region,ISO3, 
                    `Parks & Beaches`= 
                     parks_percent_change_from_baseline,
                    `Grocery & Pharmacy` = 
                     grocery_and_pharmacy_percent_change_from_baseline,
                     Residential = 
                     residential_percent_change_from_baseline,
                    `Retail & Recreation` = 
                      retail_and_recreation_percent_change_from_baseline) 

```


# Plot the regional trends for parks, pharmacies and residential

Here we extract the continent and regional information for each of the countries, reorganise the data and plot the trends in change of time spent at parks, pharmacies and residential during lockdown in Africa, Americas, Asia, Europe and Oceania.


```{r}
# Load packages
library(ggplot2);library(viridis); library(ggpubr);library(sf);library("rnaturalearth"); library("rnaturalearthdata"); library(tidyr)


# extract continent info
# These data will be used to match the world regions to the google data
world <- ne_countries(scale = "medium", returnclass = "sf")
world <- world %>% rename(ISO3 = iso_a3) 
region_un <- world$region_un
continent <- world$continent
ISO3 <- world$ISO3
continent<- tibble(ISO3, region_un, continent)


# join the regional data to the google data
google_countries <- left_join(google_countries, continent, by = "ISO3")

# assign Tuvalu to Oceania
google_countries$region_un[is.na(google_countries$region_un)] <-"Oceania"

## Define "date" as a date 
google_countries$date <- as.Date(google_countries$date)

## Rearrange for plotting
google_countries <- google_countries %>% gather(type, change, 
                                                `Parks & Beaches`:`Retail & Recreation`)


## Calculate regional median movement at parks, pharmacies and residential
google_median_regional <- google_countries %>% group_by(date, type, region_un) %>% 
      summarise(change = median(change, na.rm = TRUE))


## Create plot theme
regional_plottheme <-  theme_bw(base_size = 15)+ # set the background theme   
   theme(panel.grid.major = element_blank(), # remove the major lines
        panel.grid.minor = element_blank(), # remove the minor lines
        #axis.text.x = element_text(angle = 90), # rotate the x-axis text
        axis.title.x = element_blank(),
        strip.text.x = element_text(size = 15, color = "white"), 
        strip.background = element_rect(fill="black")) # remove x-axis title


## Explore the regional trends
# Parks and Beaches
ggplot() +
  geom_line(data = filter(google_countries, type == "Parks & Beaches"),
            aes(date, change, group = country_region),
            colour = alpha("grey", 0.5))+
  geom_line(data = filter(google_median_regional, type == "Parks & Beaches"),
            aes(date, change))+
  geom_hline(yintercept = 0, linetype = "dashed")+
  scale_x_date(date_breaks = "8 week", date_labels = "%b %d")+
  facet_wrap(~region_un, scales = "free", ncol = 3)+
  labs(y = "Change in length of visit (%)",
       title = "Parks & Beaches")+
  regional_plottheme



# Grocery & Pharmacy
ggplot() +
  geom_line(data = filter(google_countries, type == "Grocery & Pharmacy"),
            aes(date, change, group = country_region),
            colour = alpha("grey", 0.5))+
    geom_line(data = filter(google_median_regional, type == "Grocery & Pharmacy"),
            aes(date, change))+
  geom_hline(yintercept = 0, linetype = "dashed")+
  scale_x_date(date_breaks = "8 week", date_labels = "%b %d")+
  facet_wrap(~region_un, scales = "free", ncol = 3)+
  labs(y = "Change in length of visit (%)",
       title = "Grocery & Pharmacy")+
  regional_plottheme


# Residential
ggplot() +
  geom_line(data = filter(google_countries, type == "Residential"),
            aes(date, change, group = country_region),
            colour = alpha("grey", 0.5))+
  geom_line(data = filter(google_median_regional, type == "Residential"),
            aes(date, change))+
  geom_hline(yintercept = 0, linetype = "dashed")+
  scale_x_date(date_breaks = "8 week", date_labels = "%b %d")+
  facet_wrap(~region_un, scales = "free", ncol = 3)+
  labs(y = "Change in length of visit (%)",
       title = "Residential")+
  regional_plottheme

```


## Global plot for time at parks, pharmacies and residential

Here we calculate and plot the global median change of time at parks, pharmacies and residential during lockdown.

At the global scale, people returned to nature five days before (parks & beaches: 19-08-2020) they returned to get basic human needs (grocery & pharmacy: 24-08-2020), and 15 days before they returned to retail and recreation stores (03-09-2020). Date represents the day that the global median crossed zero.

```{r}

library(dplyr); library(tidyr)

## Calculate global median movement at parks, pharmacies and residential
google_median <- google %>% group_by(date) %>% 
      summarise(`Parks & Beaches`= 
                 median(parks_percent_change_from_baseline, na.rm = TRUE),
                `Grocery & Pharmacy` = 
                 median(grocery_and_pharmacy_percent_change_from_baseline, na.rm = TRUE),
                 Residential = 
                 median(residential_percent_change_from_baseline, na.rm = TRUE),
                `Retail & Recreation` = 
                  median(retail_and_recreation_percent_change_from_baseline, na.rm = TRUE))

## Define "date" as a date 
google_median$date <- as.Date(google_median$date)

## Rearrange for plotting
google_median <- google_median %>% gather(type, change, `Parks & Beaches`:`Retail & Recreation`)

## Define plot theme
global_plottheme <- theme_bw(base_size = 15)+ # set the background theme       
  theme(panel.grid.major = element_blank(), # remove the major lines
        panel.grid.minor = element_blank(), # remove the minor lines
        axis.title.x = element_blank(),
        strip.text.x = element_text(size = 15, color = "white"), 
        strip.background = element_rect(fill="black"))


## Create global plot
ggplot(google_median, aes(date, change)) +
  geom_line(data = google_countries, 
            aes(group = country_region), 
            colour = alpha("grey", 0.5))+
  geom_line(size = 1)+
  geom_vline(xintercept = as.numeric(as.Date("2020-07-28")), 
             linetype = "dashed", colour = "red", size = 1)+
  geom_hline(yintercept = 0, linetype = "dashed")+
  scale_x_date(date_breaks = "8 week", date_labels = "%b %d")+
  facet_wrap(~type, scales = "free", nrow = 2)+
  labs(y = "Change in length of visit (%)")+
  global_plottheme


# Save the plot
ggsave("Parks_grocery_residential.pdf", 
       dpi = 600, 
       width = 160, height = 200, unit = "mm")
```


#######################
## ADVANCED METHODS
#######################

1. Use GAM models to identify the anthropause date for each country based on the greatest change of people being confined to their homes (same approach as BIOC paper)

2. Find the date that each country's mobility crosses zero (e.g., "returns" to nature, necessities, luxuries)

3. Calculate the number of days between the lockdown date and the return date for each country

4. Calculate the average global and continental return days for nature, necessities, luxuries

5. Compare whether there is a global and continental difference between the return days to nature, necessities, luxuries

## Date countries cross zero

```{r}

## Join the lockdown date to the google data
google2 <- left_join(google, 
                     chosen_start %>% select(country, ISO3, julian_lockdown))


## Identify the day that a country's mobility crosses zero
## and calculate the number of days after lockdown that the 
## country's mobility crossed zero
google2 %>% group_by(country, ISO3) %>% 
            filter(julian > julian_lockdown & parks > 0) %>%
            summarise(lockdown = min(julian_lockdown),
                      parks_zero = min(julian),
                      parks_diff = parks_zero - lockdown)





```





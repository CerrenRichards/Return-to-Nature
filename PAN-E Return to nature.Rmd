---
title: "PAN-E Return to nature"
author: "Cerren Richards"
date: "14/05/2022"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Here we use the Google mobility data to explore the response of people returning to nature after COVID-19 confinements. 

#_______________________

### Google Data

**Data Description**:

* How visits and length of stay at different places change compared to a baseline.
    - Parks: national parks, public beaches, marinas, dog parks, plazas, and public gardens.
    - Residential: places of residence
    - Grocery & Pharmacy: grocery markets, food warehouses, farmers markets, 
                          specialty food shops, drug stores, and pharmacies.
    - Retail & Recreation:restaurants, cafes, shopping centers, theme parks,
                          museums, libraries, and movie theaters
    
* Baseline: Median value, for the corresponding day of the week, during the 5- week period Jan 3–Feb 6, 2020

**Download data and methods**:

* https://www.google.com/covid19/mobility/
* https://support.google.com/covid19-mobility/answer/9824897?hl=en&ref_topic=9822927
* https://www.google.com/covid19/mobility/data_documentation.html?hl=en


#_______________________

## Download the Google mobility data

In this chunk we download the Google mobility data, reorganise it and select only the overall country trends. 

```{r, error=FALSE, warning=FALSE}

# These data were downloaded in September 2022
google <- read.csv("Global_Mobility_Report_latest.csv")

library(dplyr)
# remove the subregions and metro areas and only keep the overall country pattern
google <- google %>% filter(metro_area == "" & sub_region_1 == "")


library(naniar)
# R reads Namibia's iso2 code is as an "is.na" object, so we will rename it to NA
google$country_region_code[is.na(google$country_region_code)] <-"NA"

library(countrycode)

# Add the country codes so we ensure everything matches 
google$ISO2 <- google$country_region_code
google$ISO3 <- countrycode(google$ISO2, origin = 'iso2c', destination = 'iso3c')
google$country <- countrycode(google$ISO2, origin = 'iso2c', destination = 'country.name')

# Set the date as POSIXct
google$Date <- as.POSIXct(google$date, format='%Y-%m-%d')


# Select the specific data and rename columns
google_countries <- google %>% select(country, ISO3, Date, 
                    `Nature`= 
                     parks_percent_change_from_baseline,
                    `Necessities` = 
                     grocery_and_pharmacy_percent_change_from_baseline,
                     Residential = 
                     residential_percent_change_from_baseline,
                    `Luxury` = 
                      retail_and_recreation_percent_change_from_baseline) 

```

### Remove countries

The following 12 countries will be excluded because they do not show obvious change in lockdown dates or they do not have enough data (Bates et al. (2021) Biological Conservation):

"Hong Kong SAR China", "Mongolia", "South Korea", "Taiwan", "Yemen", "Liechtenstein", "Réunion", "North Macedonia", "Tajikistan", "Antigua & Barbuda", "Aruba", "Guinea-Bissau" 


```{r}

# Remove countries from google dataframe
google_countries <- google_countries %>% 
                     filter(!country %in% c("Hong Kong SAR China", "Mongolia", 
                                            "South Korea", "Taiwan", "Yemen", 
                                            "Liechtenstein", "Réunion", "North Macedonia", 
                                            "Tajikistan", "Antigua & Barbuda", "Aruba", 
                                            "Guinea-Bissau"))

```


## Detrend Data

```{r}

# Define month
google_countries$Month <- format(google_countries$Date,"%m")
google_countries$Month <- format(google_countries$Date,"%m")
google_countries$Month <- as.numeric(google_countries$Month)



## Run a loop to extract the residuals for each country

# Create an empty list to store residuals for each country
residuals_lux <- list()
residuals_nat <- list()
residuals_nec <- list()

# Loop through each country
for (i in unique(google_countries$country)) {
  
  # Subset the data for the current country
  country_data <- subset(google_countries, country == i)
  
  # Fit the GAM models
  gam_lux <- gam(Luxury ~ s(Month), data = country_data)
  gam_nat <- gam(Nature ~ s(Month), data = country_data)
  gam_nec <- gam(Necessities ~ s(Month), data = country_data)
  
  # Extract residuals and store in the lists
  residuals_lux[[i]] <- residuals(gam_lux)
  residuals_nat[[i]] <- residuals(gam_nat)
  residuals_nec[[i]] <- residuals(gam_nec)
}


# Extract unique country categories
countries <- unique(google_countries$country)

# Add residuals back to the original dataframe
## There are some NAs in the data, so have to do a couple more steps 
## because they don't match up by just joining
## have to do this for each mobility category

# Luxury
google_countries2 <- google_countries %>% drop_na(Luxury)
google_countries2$res.Luxury <- unlist(lapply(countries, function(country) residuals_lux[[country]]))
google_countries <- left_join(google_countries, google_countries2)

# Nature
google_countries2 <- google_countries %>% drop_na(Nature)
google_countries2$res.Nature<-unlist(lapply(countries, function(country) residuals_nat[[country]]))
google_countries <- left_join(google_countries, google_countries2)

# Necessities
google_countries2 <- google_countries %>% drop_na(Necessities)
google_countries2$res.Necessities <- unlist(lapply(countries, function(country) residuals_nec[[country]]))
google_countries <- left_join(google_countries, google_countries2)




# Calculate the mean of Luxury and the model residuals for the 25 days in the
# timeseries before the pandemic was declared (Feb 15th - March 11th, 2020)
# Then calculate the difference between the means 
recenter<- google_countries %>% group_by(country) %>%  select(Luxury, res.Luxury,
                                                  Nature, res.Nature,
                                                  Necessities, res.Necessities) %>% 
  slice(1:25) %>% summarise(mean.Lux = mean(Luxury), # Luxury
                            mean.res.Lux = mean(res.Luxury),
                            diff.Lux = mean.res.Lux - mean.Lux,
                            mean.Nat = mean(Nature), # Nature
                            mean.res.Nat = mean(res.Nature),
                            diff.Nat = mean.res.Nat - mean.Nat,
                            mean.Nec = mean(Necessities), # Necessities
                            mean.res.Nec = mean(res.Necessities),
                            diff.Nec = mean.res.Nec - mean.Nec)%>%
                  select(country, diff.Lux, diff.Nat, diff.Nec)


# Join datasets
google_countries <- left_join(google_countries, recenter)

# Recenter the residuals based on the difference between the means
google_countries$center.Lux <- google_countries$res.Luxury - google_countries$diff.Lux
google_countries$center.Nat <- google_countries$res.Nature - google_countries$diff.Nat
google_countries$center.Nec <- google_countries$res.Necessities - google_countries$diff.Nec



# Plot Luxury
ggplot(google_countries) +
  theme_bw()+
  geom_point(aes(Date, Luxury))+
   #geom_point(aes(Date,res.Luxury),colour = "red", alpha = 0.4)+
   geom_point(aes(Date,center.Lux),colour = "blue",  alpha = 0.4)+
  facet_wrap(~country, scales = "free_y")


# Plot Nature
ggplot(filter(google_countries, country %in% c("United Kingdom", "Canada", "Norway"))) +
  theme_bw()+
  geom_point(aes(Date, Nature))+
   #geom_point(aes(Date,res.Nature),colour = "red", alpha = 0.4)+
   geom_point(aes(Date,center.Nat),colour = "blue",  alpha = 0.4)+
  facet_wrap(~country, scales = "free_y", ncol = 1)


# Plot Necessities
ggplot(google_countries) +
  theme_bw()+
  geom_point(aes(Date, Necessities))+
  # geom_point(aes(Date,res.Necessities),colour = "red", alpha = 0.4)+
   geom_point(aes(Date,center.Nec),colour = "blue",  alpha = 0.4)+
  facet_wrap(~country, scales = "free_y")


```


## Run GAM models through the data to describe the overall net trend

```{r}

## Add a number column to substitute for date in the model
google_countries <- google_countries %>% group_by(country) %>% mutate(time = 1:n())

# Create an empty list to store gam predictions for each country
# RAW DATA
predict_lux <- list()
predict_nat <- list()
predict_nec <- list()

# DETRENDED DATA (RESIDUALS)
predict_lux.resid <- list()
predict_nat.resid <- list()
predict_nec.resid <- list()

# Loop through each country
for (i in unique(google_countries$country)) {
  
  # Subset the data for the current country
  country_data <- subset(google_countries, country == i)
  
  # RAW DATA
  # Fit the GAM models 
  # k = 30 for the number of months in the dataset
  gam_lux.pred <- gam(Luxury ~ s(time, k = 30), data = country_data)
  gam_nat.pred <- gam(Nature ~ s(time, k = 30), data = country_data)
  gam_nec.pred <- gam(Necessities ~ s(time, k = 30), data = country_data)
  
  # Extract GAM trend line and store in the lists
  # This gives the overall net trend 
  predict_lux[[i]] <- predict.gam(gam_lux.pred, type="response")
  predict_nat[[i]] <- predict.gam(gam_nat.pred, type="response")
  predict_nec[[i]] <- predict.gam(gam_nec.pred, type="response")
  
  # DETRENDED DATA
  # Fit the GAM models 
  gam_lux.pred.resid <- gam(center.Lux ~ s(time, k = 30), data = country_data)
  gam_nat.pred.resid <- gam(center.Nat ~ s(time, k = 30), data = country_data)
  gam_nec.pred.resid <- gam(center.Nec ~ s(time, k = 30), data = country_data)
  
  # Extract gam trends and store in the lists
  predict_lux.resid[[i]] <- predict.gam(gam_lux.pred.resid, type="response")
  predict_nat.resid[[i]] <- predict.gam(gam_nat.pred.resid, type="response")
  predict_nec.resid[[i]] <- predict.gam(gam_nec.pred.resid, type="response")
}



# Add gam trends back to the original dataframe
## There are some NAs in the data, so have to do a couple more steps 
## because they don't match up by just joining
## have to do this for each mobility category

# Luxury
google_countries2 <- google_countries %>% drop_na(Luxury)
google_countries2$Luxury.pred <- unlist(lapply(countries, function(country) predict_lux[[country]]))
google_countries2$Luxury.pred.resid <- unlist(lapply(countries, function(country) predict_lux.resid[[country]]))
google_countries <- left_join(google_countries, google_countries2)

# Nature
google_countries2 <- google_countries %>% drop_na(Nature)
google_countries2$Nature.pred <- unlist(lapply(countries, function(country) predict_nat[[country]]))
google_countries2$Nature.pred.resid <- unlist(lapply(countries, function(country) predict_nat.resid[[country]]))
google_countries <- left_join(google_countries, google_countries2)

# Necessities
google_countries2 <- google_countries %>% drop_na(Necessities)
google_countries2$Necessities.pred <- unlist(lapply(countries, function(country) predict_nec[[country]]))
google_countries2$Necessities.pred.resid <- unlist(lapply(countries, function(country) predict_nec.resid[[country]]))
google_countries <- left_join(google_countries, google_countries2)


# Plot Luxury
ggplot(filter(google_countries, country %in% c("Australia", "Canada", "Costa Rica", "Zimbabwe"))) +
  theme_bw()+
  geom_point(aes(Date, Luxury), alpha = 0.2)+
   #geom_point(aes(Date,res.Luxury),colour = "red", alpha = 0.4)+
   geom_point(aes(Date,center.Lux),colour = "blue",  alpha = 0.2)+
  geom_line(aes(Date, Luxury.pred), colour = "black", size = 1.25)+
  geom_line(aes(Date, Luxury.pred.resid), colour = "blue", size = 1.25)+
  facet_wrap(~country, scales = "free_y")


# Plot Nature
ggplot(filter(google_countries, country %in% c("Australia", "Canada", "Costa Rica", "Zimbabwe"))) +
  theme_bw()+
  geom_point(aes(Date, Nature), alpha = 0.2)+
   #geom_point(aes(Date,res.Nature),colour = "red", alpha = 0.4)+
   geom_point(aes(Date,center.Nat),colour = "blue",  alpha = 0.2)+
    geom_line(aes(Date, Nature.pred), colour = "black", size = 1.25)+
  geom_line(aes(Date, Nature.pred.resid), colour = "blue", size = 1.25)+
  facet_wrap(~country, scales = "free_y")


# Plot Necessities
ggplot(filter(google_countries, country %in% c("Australia", "Canada", "Costa Rica", "Zimbabwe"))) +
  theme_bw()+
  geom_point(aes(Date, Necessities), alpha = 0.2)+
  # geom_point(aes(Date,res.Necessities),colour = "red", alpha = 0.4)+
   geom_point(aes(Date,center.Nec),colour = "blue",  alpha = 0.2)+
    geom_line(aes(Date, Necessities.pred), colour = "black", size = 1.25)+
  geom_line(aes(Date, Necessities.pred.resid), colour = "blue", size = 1.25)+
  facet_wrap(~country, scales = "free_y")

```




## Find the day people were home the most (peak lockdown)

```{r}

## Less that May 1st and the greatest at home to capture the first peak
## We select May because this is when most countries begin to ease the restrictions
## and May 1st was identified in a sensitivity test in Bates et al. (2021) Biological Conservation
home <- google_countries %>% group_by(country, ISO3) %>% 
            filter(Date <= "2020-05-01") %>%
            filter(Residential == max(Residential, na.rm = T)) %>%
            summarise(max.home = min(Date))


## Join
google_countries <- left_join(google_countries, home)


```


## Date countries cross zero

```{r}
library(tidyverse)

## Identify the day that a country's mobility crosses zero
## and calculate the number of days after lockdown that the 
## country's mobility crossed zero

## Make four different calculation for the mobility categories to 
## compare the difference between the raw vs. resid data and gam trend vs. raw data

## NATURE
# Nature raw
nature <- google_countries %>% group_by(country, ISO3) %>% 
            filter(Date > max.home & `Nature` > 0) %>%
            summarise(home =  min(max.home), # the date people were home most
                      nature_zero = min(Date), # The first date people returned to nature
                      nature_diff = nature_zero - home) # calc difference 


# Nature raw resid
nature.resid <- google_countries %>% group_by(country, ISO3) %>% 
            filter(Date > max.home & center.Nat > 0) %>%
            summarise(home =  min(max.home), # the date people were home most
                      nature_zero.resid = min(Date), # The first date people returned to nature
                      nature_diff.resid = nature_zero.resid - home) # calc difference 


# Nature raw resid
nature.gam <- google_countries %>% group_by(country, ISO3) %>% 
            filter(Date > max.home & Nature.pred > 0) %>%
            summarise(home =  min(max.home), # the date people were home most
                      nature_zero.gam = min(Date), # The first date people returned to nature
                      nature_diff.gam = nature_zero.gam - home) # calc difference 

# Nature raw resid
nature.resid.gam <- google_countries %>% group_by(country, ISO3) %>% 
            filter(Date > max.home & Nature.pred.resid > 0) %>%
            summarise(home =  min(max.home), # the date people were home most
                      nature_zero.resid.gam = min(Date), # The first date people returned to nature
                      nature_diff.resid.gam = nature_zero.resid.gam - home) # calc difference 


## NECESSITIES
# Necessities raw
Necessities <- google_countries %>% group_by(country, ISO3) %>% 
            filter(Date > max.home & `Necessities` > 0) %>%
            summarise(home =  min(max.home), # the date people were home most
                      Necessities_zero = min(Date), # The first date people returned to Necessities
                      Necessities_diff = Necessities_zero - home) # calc difference 


# Necessities raw resid
Necessities.resid <- google_countries %>% group_by(country, ISO3) %>% 
            filter(Date > max.home & center.Nec > 0) %>%
            summarise(home =  min(max.home), # the date people were home most
                      Necessities_zero.resid = min(Date), # The first date people returned to Necessities
                      Necessities_diff.resid = Necessities_zero.resid - home) # calc difference 


# Necessities raw resid
Necessities.gam <- google_countries %>% group_by(country, ISO3) %>% 
            filter(Date > max.home & Necessities.pred > 0) %>%
            summarise(home =  min(max.home), # the date people were home most
                      Necessities_zero.gam = min(Date), # The first date people returned to Necessities
                      Necessities_diff.gam = Necessities_zero.gam - home) # calc difference 

# Necessities raw resid
Necessities.resid.gam <- google_countries %>% group_by(country, ISO3) %>% 
            filter(Date > max.home & Necessities.pred.resid > 0) %>%
            summarise(home =  min(max.home), # the date people were home most
                      Necessities_zero.resid.gam = min(Date), # The first date people returned to Necessities
                      Necessities_diff.resid.gam = Necessities_zero.resid.gam - home) # calc difference 




## LUXURY
# Luxury raw
Luxury <- google_countries %>% group_by(country, ISO3) %>% 
            filter(Date > max.home & `Luxury` > 0) %>%
            summarise(home =  min(max.home), # the date people were home most
                      Luxury_zero = min(Date), # The first date people returned to Luxury
                      Luxury_diff = Luxury_zero - home) # calc difference 


# Luxury raw resid
Luxury.resid <- google_countries %>% group_by(country, ISO3) %>% 
            filter(Date > max.home & center.Lux > 0) %>%
            summarise(home =  min(max.home), # the date people were home most
                      Luxury_zero.resid = min(Date), # The first date people returned to Luxury
                      Luxury_diff.resid = Luxury_zero.resid - home) # calc difference 


# Luxury raw resid
Luxury.gam <- google_countries %>% group_by(country, ISO3) %>% 
            filter(Date > max.home & Luxury.pred > 0) %>%
            summarise(home =  min(max.home), # the date people were home most
                      Luxury_zero.gam = min(Date), # The first date people returned to Luxury
                      Luxury_diff.gam = Luxury_zero.gam - home) # calc difference 

# Luxury raw resid
Luxury.resid.gam <- google_countries %>% group_by(country, ISO3) %>% 
            filter(Date > max.home & Luxury.pred.resid > 0) %>%
            summarise(home =  min(max.home), # the date people were home most
                      Luxury_zero.resid.gam = min(Date), # The first date people returned to Luxury
                      Luxury_diff.resid.gam = Luxury_zero.resid.gam - home) # calc difference 


## Join all data
## Join all the nature dataframes
returns <- left_join(nature, nature.resid)%>% ## nature
          left_join(., nature.gam) %>%
          left_join(., nature.resid.gam) %>%
          left_join(., Luxury) %>% ## luxury
          left_join(., Luxury.resid) %>%
          left_join(., Luxury.gam) %>%
          left_join(., Luxury.resid.gam) %>%
          left_join(., Necessities) %>% ## necessities
          left_join(., Necessities.resid) %>%
          left_join(., Necessities.gam) %>%
          left_join(., Necessities.resid.gam)


# Global median for return dates

# NECESSITIES
median(returns$Necessities_diff, na.rm = T) # 48 after peak lockdown
median(returns$Necessities_diff.resid, na.rm = T) # 77 days
median(returns$Necessities_diff.gam, na.rm = T) # 106 days
median(returns$Necessities_diff.resid.gam, na.rm = T) # 313 days

# NATURE
median(returns$nature_diff, na.rm = T) # 76 after peak lockdown
median(returns$nature_diff.resid, na.rm = T) # 129 days
median(returns$nature_diff.gam, na.rm = T) # 97 days
median(returns$nature_diff.resid.gam, na.rm = T) # 259 days

# LUXURY
median(returns$Luxury_diff, na.rm = T) # 153 after peak lockdown
median(returns$Luxury_diff.resid, na.rm = T) # 324 days
median(returns$Luxury_diff.gam, na.rm = T) # 398 days
median(returns$Luxury_diff.resid.gam, na.rm = T) # 513 days

```




# Continental differences

```{r}

# Load packages
library(ggplot2);library(viridis); library(ggpubr);library(sf);library("rnaturalearth"); library("rnaturalearthdata"); library(tidyr)


# extract continent info
# These data will be used to match the world regions to the google data
world <- ne_countries(scale = "medium", returnclass = "sf")
world <- world %>% rename(ISO3 = iso_a3) 
region_un <- world$region_un
continent <- world$continent
subregion <- world$subregion
ISO3 <- world$ISO3
continent<- tibble(ISO3, region_un, continent, subregion)


# join the regional data to the google data
returns <- left_join(returns, continent, by = "ISO3")

# assign Tuvalu to Oceania
returns$region_un[is.na(returns$region_un)] <-"Oceania"


```


## Create World Map Plot

```{r}

#Get world map info
world_map <- map_data("world") %>%  
              group_by(region) %>% 
              summarise(long=mean(long),
                        lat=mean(lat)) %>%
              rename(country = region)

# Join the data
returns <- left_join(returns, world_map)


## Pulse back
## Summarise the subregion/continental differences
regions.pulse <- returns %>% group_by(subregion) %>% 
            summarise(nature = median(nature_diff, na.rm = T),
                      nature.res = median(nature_diff.resid, na.rm = T),
                      necessities = median(Necessities_diff, na.rm = T),
                      necessities.res = median(Necessities_diff.resid, na.rm = T),
                      luxuries = median(Luxury_diff, na.rm = T),
                      luxuries.res = median(Luxury_diff.resid, na.rm = T),
                      long=mean(long, na.rm = T),
                      lat=mean(lat, na.rm = T),
                      countries = n()) %>%
            arrange(nature)



## Overall net trend
## Summarise the subregion/continental differences
regions.trend <- returns %>% group_by(subregion) %>% 
            summarise(nature = median(nature_diff.gam, na.rm = T),
                      nature.res = median(nature_diff.resid.gam, na.rm = T),
                      necessities = median(Necessities_diff.gam, na.rm = T),
                      necessities.res = median(Necessities_diff.resid.gam, na.rm = T),
                      luxuries = median(Luxury_diff.gam, na.rm = T),
                      luxuries.res = median(Luxury_diff.resid.gam, na.rm = T),
                      long=mean(long, na.rm = T),
                      lat=mean(lat, na.rm = T),
                      countries = n()) %>%
            arrange(nature)


# Save
write.csv(regions.pulse, "regions_pulse.csv")
write.csv(regions.trend, "regions_trend.csv")

## Colour countries that we have used
# Set colors
world <- mutate(world, fill = ifelse(ISO3 %in% returns$ISO3, 
                                     "Monitored", "Non-monitored"))


## Set the map theme
maptheme <-  theme_bw(base_size = 15)+
  theme(axis.title.y = element_blank(), 
        axis.title.x = element_blank(),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        legend.title = element_blank(),
        legend.position="none",
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())


# World map with dots for locations
map.plot<- ggplot() +
    geom_sf(data = world, fill = "snow3", colour = "snow3", size = 0.2) +
     maptheme+
    geom_sf(data = world, aes(fill = fill), colour = "cornsilk", size = 0.01) +
    scale_fill_manual(values = c("cornsilk", "snow3"))+
    geom_point(data = regions.pulse, 
               aes(x = long, y = lat),
               shape=21)+
    coord_sf(xlim = c(-180, 220), ylim = c(-65, 120), expand = FALSE)



# Save the plot
ggsave("map plot.pdf", 
       width = 180, height = 150, unit = "mm")

```

## Bar plots of regional trends - Pulse back - Raw data

```{r}

# Gather the data for plotting
map.regions <- regions.pulse %>% 
            select(subregion, countries, 
                   nature, luxuries, necessities, 
                   long, lat)  %>%
            gather(Mobility, Difference, nature:necessities)

# define for plotting
map.regions$mob <- "mob"

## Set plot theme
plot.theme <-  theme_void()+
  theme(legend.title = element_blank(),
        legend.position="none")


## Wrap the text into two lines when names are too long
library(stringr)
map.regions$subregion2 <-str_wrap(map.regions$subregion, 20)


library(viridis)

## plot the number of day after peak lockdown
bars <- ggplot(data = map.regions,
       aes(x = mob, y = Difference, fill = Mobility)) +
     scale_fill_viridis(discrete = TRUE, direction = -1)+
    geom_bar(stat= "identity",width = 0.3, position = position_dodge(0.35))+
    facet_wrap(~subregion2, strip.position = "bottom")+
    plot.theme


# Save the plot
ggsave("bars_plot_pulse_raw.pdf", 
       width = 150, height = 90, unit = "mm")
```

## Bar plot - Pulse back - Detrended seasonal data

```{r}

# Gather the data for plotting
map.regions.res <- regions.pulse %>% 
            select(subregion, countries, 
                   nature.res, luxuries.res, necessities.res, 
                   long, lat)  %>%
            gather(Mobility, Difference, nature.res:necessities.res)

# define for plotting
map.regions.res$mob <- "mob"

## Wrap the text into two lines when names are too long
map.regions.res$subregion2 <-str_wrap(map.regions.res$subregion, 20)


## plot the number of day after peak lockdown
 ggplot(data = map.regions.res,
       aes(x = mob, y = Difference, fill = Mobility)) +
     scale_fill_viridis(discrete = TRUE, direction = -1)+
    geom_bar(stat= "identity",width = 0.3, position = position_dodge(0.35))+
    facet_wrap(~subregion2, strip.position = "bottom")+
    plot.theme


# Save the plot
ggsave("bars_plot_pulse_resid.pdf", 
       width = 150, height = 90, unit = "mm")

```

## Bar plots of regional trends - overall trend - Raw gam

```{r}

# Gather the data for plotting
map.regions.trend <- regions.trend %>% 
            select(subregion, countries, 
                   nature, luxuries, necessities, 
                   long, lat)  %>%
            gather(Mobility, Difference, nature:necessities)

# define for plotting
map.regions.trend$mob <- "mob"

## Wrap the text into two lines when names are too long
map.regions.trend$subregion2 <-str_wrap(map.regions.trend$subregion, 20)

## plot the number of day after peak lockdown
ggplot(data = map.regions.trend,
       aes(x = mob, y = Difference, fill = Mobility)) +
     scale_fill_viridis(discrete = TRUE, direction = -1)+
    geom_bar(stat= "identity",width = 0.3, position = position_dodge(0.35))+
    facet_wrap(~subregion2, strip.position = "bottom")+
    plot.theme


# Save the plot
ggsave("bars_plot_pulse_raw.pdf", 
       width = 150, height = 90, unit = "mm")
```

## Bar plot - Pulse back - Detrended seasonal data

```{r}

# Gather the data for plotting
map.regions.res.trend <- regions.trend %>% 
            select(subregion, countries, 
                   nature.res, luxuries.res, necessities.res, 
                   long, lat)  %>%
            gather(Mobility, Difference, nature.res:necessities.res)

# define for plotting
map.regions.res.trend$mob <- "mob"

## Wrap the text into two lines when names are too long
map.regions.res.trend$subregion2 <-str_wrap(map.regions.res.trend$subregion, 20)


## plot the number of day after peak lockdown
 ggplot(data = map.regions.res.trend,
       aes(x = mob, y = Difference, fill = Mobility)) +
     scale_fill_viridis(discrete = TRUE, direction = -1)+
    geom_bar(stat= "identity",width = 0.3, position = position_dodge(0.35))+
    facet_wrap(~subregion2, strip.position = "bottom")+
    plot.theme


# Save the plot
ggsave("bars_plot_pulse_resid.pdf", 
       width = 150, height = 90, unit = "mm")

```



## Global plot for time at nature, necessities, luxuries

Here we calculate and plot the global median change of time at nature, necessities, luxuries after lockdown.


```{r}
library(dplyr); library(tidyr)

## Calculate global median movement at nature, necessities, luxuries
google_median <- google_countries %>% group_by(Date) %>% 
      summarise(Nature = median(Nature, na.rm = TRUE),
                Necessities = median(Necessities, na.rm = TRUE),
                Luxury = median(Luxury, na.rm = TRUE))


## Rearrange for plotting
google_median <- google_median %>% gather(type, change, Nature:Luxury)

## Define plot theme
global_plottheme <- theme_bw(base_size = 15)+ # set the background theme       
  theme(panel.grid.major = element_blank(), # remove the major lines
        panel.grid.minor = element_blank(), # remove the minor lines
        axis.title.x = element_blank(),
        strip.text.x = element_text(size = 15, color = "white"), 
        strip.background = element_rect(fill="black"),
        legend.title = element_blank(),
        legend.position="none")


## Create global plot
timeplot<- ggplot(google_median, aes(Date, change)) +
  geom_line( aes(colour = type))+
  geom_hline(yintercept = 0, linetype = "dashed")+
  labs(y = "Change in length \n of visit (%)")+
  scale_colour_viridis(discrete = TRUE, direction = -1)+
  global_plottheme


# Save the plot
ggsave("time plot.pdf", 
       width = 180, height = 75, unit = "mm")

```




## Combine the plots 

We manually place the bar plots onto the map.

```{r}

library(patchwork)

map.plot / timeplot + plot_layout(height=c(2,1))

# Install ggview
remotes::install_github("idmn/ggview")
library(ggview)
ggview(units = "mm", width = 150, height = 90)

```


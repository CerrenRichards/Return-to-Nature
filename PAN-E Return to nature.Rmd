---
title: "PAN-E Return to nature"
author: "Cerren Richards"
date: "14/05/2022"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Here we use the Google mobility data to explore the response of people returning to nature after COVID-19 confinements.

#_______________________

### Google Data

**Data Description**:

* How visits and length of stay at different places change compared to a baseline.
    - Parks: national parks, public beaches, marinas, dog parks, plazas, and public gardens.
    - Residential: places of residence
    - Grocery & Pharmacy: grocery markets, food warehouses, farmers markets, 
                          specialty food shops, drug stores, and pharmacies.
    - Retail & Recreation:restaurants, cafes, shopping centers, theme parks,
                          museums, libraries, and movie theaters
    
* Baseline: Median value, for the corresponding day of the week, during the 5- week period Jan 3â€“Feb 6, 2020

**Download data and methods**:

* https://www.google.com/covid19/mobility/
* https://support.google.com/covid19-mobility/answer/9824897?hl=en&ref_topic=9822927
* https://www.google.com/covid19/mobility/data_documentation.html?hl=en


#_______________________

#######################
## SIMPLIFIED METHODS
#######################

## Download the Google mobility data

In this chunk we download the Google mobility data, reorganise it and select only the overall country trends. 

```{r, error=FALSE, warning=FALSE}

# These data were downloaded in October 2020
google <- readRDS(file = "Global_Mobility_Report.rds")

# R reads Namibia's iso2 code is as an "is.na" object, so we will rename it to NA
google$country_region_code[is.na(google$country_region_code)] <-"NA"

library(countrycode)

# Add the country codes so we ensure everything matches 
google$ISO2 <- google$country_region_code
google$ISO3 <- countrycode(google$ISO2, origin = 'iso2c', destination = 'iso3c')
google$country <- countrycode(google$ISO2, origin = 'iso2c', destination = 'country.name')

# Add Julian date
google$julian<- (strptime(google$date, "%Y-%m-%d")$yday) + 1 # need to add 1 day because 2020 is a leap year

library(naniar)

# remove the subregions and only keep the overall country pattern
google <- google %>% replace_with_na(replace = list(sub_region_1 = ""))
google <- google[is.na(google$sub_region_1),]

library(dplyr)

# Select the specific data and rename columns
google_countries <- google %>% select(country, ISO3, date,  julian,
                    `Parks & Beaches`= 
                     parks_percent_change_from_baseline,
                    `Grocery & Pharmacy` = 
                     grocery_and_pharmacy_percent_change_from_baseline,
                     Residential = 
                     residential_percent_change_from_baseline,
                    `Retail & Recreation` = 
                      retail_and_recreation_percent_change_from_baseline) 

```


# Plot the regional trends for parks, pharmacies and residential

Here we extract the continent and regional information for each of the countries, reorganise the data and plot the trends in change of time spent at parks, pharmacies and residential during lockdown in Africa, Americas, Asia, Europe and Oceania.


```{r}
# Load packages
library(ggplot2);library(viridis); library(ggpubr);library(sf);library("rnaturalearth"); library("rnaturalearthdata"); library(tidyr)


# extract continent info
# These data will be used to match the world regions to the google data
world <- ne_countries(scale = "medium", returnclass = "sf")
world <- world %>% rename(ISO3 = iso_a3) 
region_un <- world$region_un
continent <- world$continent
ISO3 <- world$ISO3
continent<- tibble(ISO3, region_un, continent)


# join the regional data to the google data
google_countries <- left_join(google_countries, continent, by = "ISO3")

# assign Tuvalu to Oceania
google_countries$region_un[is.na(google_countries$region_un)] <-"Oceania"

## Define "date" as a date 
google_countries$date <- as.Date(google_countries$date)

## Rearrange for plotting
google_countries <- google_countries %>% gather(type, change, 
                                                `Parks & Beaches`:`Retail & Recreation`)


## Calculate regional median movement at parks, pharmacies and residential
google_median_regional <- google_countries %>% group_by(date, type, region_un) %>% 
      summarise(change = median(change, na.rm = TRUE))


## Create plot theme
regional_plottheme <-  theme_bw(base_size = 15)+ # set the background theme   
   theme(panel.grid.major = element_blank(), # remove the major lines
        panel.grid.minor = element_blank(), # remove the minor lines
        #axis.text.x = element_text(angle = 90), # rotate the x-axis text
        axis.title.x = element_blank(),
        strip.text.x = element_text(size = 15, color = "white"), 
        strip.background = element_rect(fill="black")) # remove x-axis title


## Explore the regional trends
# Parks and Beaches
ggplot() +
  geom_line(data = filter(google_countries, type == "Parks & Beaches"),
            aes(date, change, group = country_region),
            colour = alpha("grey", 0.5))+
  geom_line(data = filter(google_median_regional, type == "Parks & Beaches"),
            aes(date, change))+
  geom_hline(yintercept = 0, linetype = "dashed")+
  scale_x_date(date_breaks = "8 week", date_labels = "%b %d")+
  facet_wrap(~region_un, scales = "free", ncol = 3)+
  labs(y = "Change in length of visit (%)",
       title = "Parks & Beaches")+
  regional_plottheme



# Grocery & Pharmacy
ggplot() +
  geom_line(data = filter(google_countries, type == "Grocery & Pharmacy"),
            aes(date, change, group = country_region),
            colour = alpha("grey", 0.5))+
    geom_line(data = filter(google_median_regional, type == "Grocery & Pharmacy"),
            aes(date, change))+
  geom_hline(yintercept = 0, linetype = "dashed")+
  scale_x_date(date_breaks = "8 week", date_labels = "%b %d")+
  facet_wrap(~region_un, scales = "free", ncol = 3)+
  labs(y = "Change in length of visit (%)",
       title = "Grocery & Pharmacy")+
  regional_plottheme


# Residential
ggplot() +
  geom_line(data = filter(google_countries, type == "Residential"),
            aes(date, change, group = country_region),
            colour = alpha("grey", 0.5))+
  geom_line(data = filter(google_median_regional, type == "Residential"),
            aes(date, change))+
  geom_hline(yintercept = 0, linetype = "dashed")+
  scale_x_date(date_breaks = "8 week", date_labels = "%b %d")+
  facet_wrap(~region_un, scales = "free", ncol = 3)+
  labs(y = "Change in length of visit (%)",
       title = "Residential")+
  regional_plottheme

```


## Global plot for time at parks, pharmacies and residential

Here we calculate and plot the global median change of time at parks, pharmacies and residential during lockdown.

At the global scale, people returned to nature five days before (parks & beaches: 19-08-2020) they returned to get basic human needs (grocery & pharmacy: 24-08-2020), and 15 days before they returned to retail and recreation stores (03-09-2020). Date represents the day that the global median crossed zero.

```{r}

library(dplyr); library(tidyr)

## Calculate global median movement at parks, pharmacies and residential
google_median <- google %>% group_by(date) %>% 
      summarise(`Parks & Beaches`= 
                 median(parks_percent_change_from_baseline, na.rm = TRUE),
                `Grocery & Pharmacy` = 
                 median(grocery_and_pharmacy_percent_change_from_baseline, na.rm = TRUE),
                 Residential = 
                 median(residential_percent_change_from_baseline, na.rm = TRUE),
                `Retail & Recreation` = 
                  median(retail_and_recreation_percent_change_from_baseline, na.rm = TRUE))

## Define "date" as a date 
google_median$date <- as.Date(google_median$date)

## Rearrange for plotting
google_median <- google_median %>% gather(type, change, `Parks & Beaches`:`Retail & Recreation`)

## Define plot theme
global_plottheme <- theme_bw(base_size = 15)+ # set the background theme       
  theme(panel.grid.major = element_blank(), # remove the major lines
        panel.grid.minor = element_blank(), # remove the minor lines
        axis.title.x = element_blank(),
        strip.text.x = element_text(size = 15, color = "white"), 
        strip.background = element_rect(fill="black"))


## Create global plot
ggplot(google_median, aes(date, change)) +
  geom_line(data = google_countries, 
            aes(group = country_region), 
            colour = alpha("grey", 0.5))+
  geom_line(size = 1)+
  geom_vline(xintercept = as.numeric(as.Date("2020-07-28")), 
             linetype = "dashed", colour = "red", size = 1)+
  geom_hline(yintercept = 0, linetype = "dashed")+
  scale_x_date(date_breaks = "8 week", date_labels = "%b %d")+
  facet_wrap(~type, scales = "free", nrow = 2)+
  labs(y = "Change in length of visit (%)")+
  global_plottheme



# Save the plot
ggsave("Parks_grocery_residential.pdf", 
       dpi = 600, 
       width = 160, height = 200, unit = "mm")
```


#######################
## ADVANCED METHODS
#######################

1. Use GAM models to identify the anthropause date for each country based on the greatest change of people being confined to their homes (same approach as BIOC paper)

2. Find the date that each country's mobility crosses zero (e.g., "returns" to nature, necessities, luxuries)

3. Calculate the number of days between the lockdown date and the return date for each country

4. Calculate the average global and continental return days for nature, necessities, luxuries

5. Compare whether there is a global and continental difference between the return days to nature, necessities, luxuries


## Download the Google mobility data

In this chunk we download the Google mobility data, reorganise it and select only the overall country trends. 

```{r, error=FALSE, warning=FALSE}

# These data were downloaded in October 2020
google <- readRDS(file = "Global_Mobility_Report.rds")

# These data were downloaded in September 2022
google <- read.csv("Global_Mobility_Report_latest.csv")

# Filter for only 2020 data
google$date2 <- as.Date(google$date)
google <- google %>% filter(date2 <= "2020-12-31")

# R reads Namibia's iso2 code is as an "is.na" object, so we will rename it to NA
google$country_region_code[is.na(google$country_region_code)] <-"NA"

library(countrycode)

# Add the country codes so we ensure everything matches 
google$ISO2 <- google$country_region_code
google$ISO3 <- countrycode(google$ISO2, origin = 'iso2c', destination = 'iso3c')
google$country <- countrycode(google$ISO2, origin = 'iso2c', destination = 'country.name')

# Add Julian date
google$julian<- (strptime(google$date, "%Y-%m-%d")$yday) + 1 # need to add 1 day because 2020 is a leap year

library(naniar)

# remove the subregions and metro areas and only keep the overall country pattern
google <- google %>% filter(metro_area == "" & sub_region_1 == "")

library(dplyr)

# Select the specific data and rename columns
google_countries <- google %>% select(country, ISO3, date,  julian,
                    `Parks & Beaches`= 
                     parks_percent_change_from_baseline,
                    `Grocery & Pharmacy` = 
                     grocery_and_pharmacy_percent_change_from_baseline,
                     Residential = 
                     residential_percent_change_from_baseline,
                    `Retail & Recreation` = 
                      retail_and_recreation_percent_change_from_baseline) 

```


### COVID-19 Confinement Data

The Oxford Covid-19 Government Response Tracker (OxCGRT) has compiled dates for eight different confinement types and their severity (0-4).

Data info: https://github.com/OxCGRT/covid-policy-tracker

The data are constantly being updated, therefore the link may change in the future.

```{r, eval=FALSE}
library(RCurl)

# Call the OxCGRT data from GitHub
confinement <- getURL("https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker-legacy/main/legacy_data_202207/OxCGRT_latest.csv")


# Set up the confinement data for further analyses
conf <- read.csv(text=confinement) %>% 
  mutate(julian=(strptime(Date, "%Y%m%d")$yday)+1) %>% # assign Julian Date
  mutate(Date=as.Date(strptime(Date, "%Y%m%d"))) %>% # Set as a date 
  mutate(weekday=weekdays(Date)) %>% # Identify weekdays
  mutate(weekend=ifelse(grepl("Sat|Sun", weekday), 1,0)) %>% # Assign columns for weekends
  select(ISO3=CountryCode, RegionName, Date, julian, weekday, weekend, # Select columns
         C1_School.closing, C2_Workplace.closing, C3_Cancel.public.events,
         C4_Restrictions.on.gatherings, C5_Close.public.transport,
         C6_Stay.at.home.requirements, C7_Restrictions.on.internal.movement) %>%
  filter(Date <="2020-09-11")

# Remove subregions
conf <- conf %>% filter(RegionName == "")

```


### SENSITIVITY ANALYSIS and Extract t-statistic for each country

We divided each countryâ€™s mobility data into â€˜beforeâ€™ and â€˜afterâ€™ periods for each confinement type and level, ran generalised additive models to determine which division best characterised the observed changes in mobility patterns. 

```{r, eval = FALSE}

# Sensitivity analysis to identify the best cut off dates
# We select May because this is when most countries begin to ease the restrictions
maystart <- 122 # Julian date for May 1st
maymid <- 136 # May 15
mayend <- 152 # May 30

# Subset the google data
googlestart <- subset(google_countries,  julian <= maystart)
googlemid <- subset(google_countries,  julian <= maymid)
googleend <- subset(google_countries,  julian <= mayend)

# Join the Google data with the confinement data
googlestart <- left_join(googlestart, conf, by = c("ISO3", "julian"))
googlemid <- left_join(googlemid, conf, by = c("ISO3", "julian"))
googleend <- left_join(googleend, conf, by = c("ISO3", "julian"))


# List seven of the confinement types 
conftypes=c("C1_School.closing", "C2_Workplace.closing", "C3_Cancel.public.events",
            "C4_Restrictions.on.gatherings", "C5_Close.public.transport",
            "C6_Stay.at.home.requirements", "C7_Restrictions.on.internal.movement")

###_________________________________________
### MID MAY
###_________________________________________

# Create empty spaces for results to be pasted
country=ISO3=restriction=level=date=character() # set as character
aics=R2=t.lockdown=pval=numeric() # set as numeric

# Create empty dataframes and lists for model outputs
country.results=subdat.list=chosen_mid=data.frame()
mod.list=country.results=list()

library(mgcv)
library(lubridate)

# Run loop to extract the t-statistic
for(i in unique(googlemid$country)){
  for(j in conftypes){
    subdat=subset(googlemid, country==i)  
    locklevels=unique(subdat[[j]])
    locklevels=locklevels[which(locklevels %in% c(1:10))]
    for(k in locklevels){
      subdat$lockdown=(subdat[[j]]==k)*1
      subdat$lockdown.type=j
      subdat$level=k
      mod=try(gam(Residential ~ lockdown + weekend + s(julian), data=subdat))
      if(!class(mod)[1]=="try-error"){
        country=c(country,i)
        ISO3=c(ISO3, subdat$ISO3[1])
        restriction=c(restriction,j)
        level=c(level,k)
        aics=c(aics,AIC(mod))
        R2=c(R2, summary(mod)$r.sq)
        t.lockdown=c(t.lockdown, summary(mod)$p.table["lockdown","t value"])
        pval=c(pval, summary(mod)$p.table["lockdown","Pr(>|t|)"])
        date=c(date, subdat$date[min(which(subdat$lockdown==1))])
      

        # save models and subdata
        mod.list[[paste(i,j,k, sep="_")]]=mod
        subdat.list=rbind(subdat.list, subset(subdat, 
                                              select=c("country", "date", "julian", "weekday",
                                                       "lockdown.type","level",  "Residential",
                                                        "lockdown")))
        
      }
    }
  }
  
  # select country top model
  country.out=data.frame(country, ISO3, restriction, level, aics, R2, t.lockdown, pval, date) %>%
    mutate(Date=ymd(date)) %>%
    subset(country==i) %>% 
    arrange(aics)
  
  country.results=rbind(country.results,country.out)
  
  country.out=subset(country.out, t.lockdown==max(t.lockdown))
  country.out$model = with(country.out, paste(country, restriction, level, sep="_"))
  
  # add top model outputs to list
  chosen_mid=rbind(chosen_mid,country.out)
  
  print(paste(i))
}

# Assign Julian date for the confinement date
chosen_mid$julian_lockdown <- (strptime(chosen_mid$date, "%Y-%m-%d")$yday) + 1 

chosen_mid<- distinct(chosen_mid, country, .keep_all = TRUE)

# Find median AIC score for all countries
median(chosen_mid$aics) #447

###_________________________________________
### END MAY
###_________________________________________


# Create empty spaces for results to be pasted
country=ISO3=restriction=level=date=character() # set as character
aics=R2=t.lockdown=pval=numeric() # set as numeric

# Create empty dataframes and lists for model outputs
country.results=subdat.list=chosen_end=data.frame()
mod.list=country.results=list()


# Run loop to extract the t-statistic
for(i in unique(googleend$country)){
  for(j in conftypes){
    subdat=subset(googleend, country==i)  
    locklevels=unique(subdat[[j]])
    locklevels=locklevels[which(locklevels %in% c(1:10))]
    for(k in locklevels){
      subdat$lockdown=(subdat[[j]]==k)*1
      subdat$lockdown.type=j
      subdat$level=k
      mod=try(gam(Residential ~ lockdown + weekend + s(julian), data=subdat))
      if(!class(mod)[1]=="try-error"){
        country=c(country,i)
        ISO3=c(ISO3, subdat$ISO3[1])
        restriction=c(restriction,j)
        level=c(level,k)
        aics=c(aics,AIC(mod))
        R2=c(R2, summary(mod)$r.sq)
        t.lockdown=c(t.lockdown, summary(mod)$p.table["lockdown","t value"])
        pval=c(pval, summary(mod)$p.table["lockdown","Pr(>|t|)"])
        date=c(date, subdat$date[min(which(subdat$lockdown==1))])
      

        # save models and subdata
        mod.list[[paste(i,j,k, sep="_")]]=mod
        subdat.list=rbind(subdat.list, subset(subdat, 
                                              select=c("country", "date", "julian", "weekday",
                                                       "lockdown.type","level",  "Residential",
                                                        "lockdown")))
        
      }
    }
  }
  
  # select country top model
  country.out=data.frame(country, ISO3, restriction, level, aics, R2, t.lockdown, pval, date) %>%
    mutate(Date=ymd(date)) %>%
    subset(country==i) %>% 
    arrange(aics)
  
  country.results=rbind(country.results,country.out)
  
  country.out=subset(country.out, t.lockdown==max(t.lockdown))
  country.out$model = with(country.out, paste(country, restriction, level, sep="_"))
  
  # add top model outputs to list
  chosen_end=rbind(chosen_end,country.out)
  
  print(paste(i))
}

# Assign Julian date for the confinement date
chosen_end$julian_lockdown <- (strptime(chosen_end$date, "%Y-%m-%d")$yday) + 1 


chosen_end<- distinct(chosen_end, country, .keep_all = TRUE)

# Find median AIC score for all countries
median(chosen_end$aics) #534


###_________________________________________
### START MAY
###_________________________________________

# Create empty spaces for results to be pasted
country=ISO3=restriction=level=date=character() # set as character
aics=R2=t.lockdown=pval=numeric() # set as numeric

# Create empty dataframes and lists for model outputs
country.results=subdat.list=chosen_start=data.frame()
mod.list=country.results=list()

# Run loop to extract the t-statistic
for(i in unique(googlestart$country)){
  for(j in conftypes){
    subdat=subset(googlestart, country==i)  
    locklevels=unique(subdat[[j]])
    locklevels=locklevels[which(locklevels %in% c(1:10))]
    for(k in locklevels){
      subdat$lockdown=(subdat[[j]]==k)*1
      subdat$lockdown.type=j
      subdat$level=k
      mod=try(gam(Residential ~ lockdown + weekend + s(julian), data=subdat))
      if(!class(mod)[1]=="try-error"){
        country=c(country,i)
        ISO3=c(ISO3, subdat$ISO3[1])
        restriction=c(restriction,j)
        level=c(level,k)
        aics=c(aics,AIC(mod))
        R2=c(R2, summary(mod)$r.sq)
        t.lockdown=c(t.lockdown, summary(mod)$p.table["lockdown","t value"])
        pval=c(pval, summary(mod)$p.table["lockdown","Pr(>|t|)"])
        date=c(date, subdat$date[min(which(subdat$lockdown==1))])
      

        # save models and subdata
        mod.list[[paste(i,j,k, sep="_")]]=mod
        subdat.list=rbind(subdat.list, subset(subdat, 
                                              select=c("country", "date", "julian", "weekday",
                                                       "lockdown.type","level",  "Residential",
                                                        "lockdown")))
        
      }
    }
  }
  
  # select country top model
  country.out=data.frame(country, ISO3, restriction, level, aics, R2, t.lockdown, pval, date) %>%
    mutate(date=ymd(date)) %>%
    subset(country==i) %>% 
    arrange(aics)
  
  country.results=rbind(country.results,country.out)
  
  country.out=subset(country.out, t.lockdown==max(t.lockdown))
  country.out$model = with(country.out, paste(country, restriction, level, sep="_"))
  
  # add top model outputs to list
  chosen_start=rbind(chosen_start,country.out)
  
  print(paste(i))
}

# Assign Julian date for the confinement date
chosen_start$julian_lockdown <- (strptime(chosen_start$date, "%Y-%m-%d")$yday) + 1 

# Remove duplicated countries (that have the same AIC score for multiple confinement types)
chosen_start<- distinct(chosen_start, country, .keep_all = TRUE)

# Find median AIC score for all countries
median(chosen_start$aics) #379


# The start of May is the most effective at identifying the lockdown dates
# Therefore we will use these dates for further analysis
lockdown <- chosen_start %>% select(country, ISO3, julian_lockdown)

```



### Plot the individual country trends with lockdown date

```{r, eval = FALSE}

# Join the lockdown dates to the full Google data for plotting
googleplots <- left_join(googlestart, chosen_start, by = c("country", "ISO3"))

library(ggplot2)
library(ggforce)
## PLOT
ggplot(data = googleplots, aes(x=julian, y=Residential)) + 
  geom_line() + 
  facet_wrap_paginate(~country, ncol = 7, nrow = 7, scale="free_y", page = 1)+
  geom_vline(aes(xintercept = julian_lockdown), colour = "red")

ggplot(data = googleplots, aes(x=julian, y=Residential)) + 
  geom_line() + 
  facet_wrap_paginate(~country, ncol = 7, nrow = 7, scale="free_y", page = 2)+
  geom_vline(aes(xintercept = julian_lockdown), colour = "red")

ggplot(data = googleplots, aes(x=julian, y=Residential)) + 
  geom_line() + 
  facet_wrap_paginate(~country, ncol = 7, nrow = 7, scale="free_y", page = 3)+
  geom_vline(aes(xintercept = julian_lockdown), colour = "red")



```


### Remove countries

The following 12 countries will be excluded because they do not show obvious change in lockdown dates or they do not have enough data:

"Hong Kong SAR China", "Mongolia", "South Korea", "Taiwan", "Yemen", "Liechtenstein", "RÃ©union", "North Macedonia", "Tajikistan", "Antigua & Barbuda", "Aruba", "Guinea-Bissau" 


```{r}

# Remove countries from google dataframe
google_countries <- google_countries %>% 
                     filter(!country %in% c("Hong Kong SAR China", "Mongolia", 
                                            "South Korea", "Taiwan", "Yemen", 
                                            "Liechtenstein", "RÃ©union", "North Macedonia", 
                                            "Tajikistan", "Antigua & Barbuda", "Aruba", 
                                            "Guinea-Bissau"))

# Remove countries from lockdown dates dataframe
lockdown <- lockdown %>% 
                     filter(!country %in% c("Hong Kong SAR China", "Mongolia", 
                                            "South Korea", "Taiwan", "Yemen", 
                                            "Liechtenstein", "RÃ©union", "North Macedonia", 
                                            "Tajikistan", "Antigua & Barbuda", "Aruba", 
                                            "Guinea-Bissau"))

```


### Find the date for countries that dont work

The models above did not select appropriate dates. We therefore manually select the dates for the following seven countries:

"Bahrain", "Belize", "Cambodia", "Italy", "Indonesia",  "Portugal",  "Vietnam"


```{r}

# Subset the countries that the model did not select an appropriate confinement date

# Set Julian date
country.results$julian_lockdown <- (strptime(country.results$date, "%Y-%m-%d")$yday) + 1 

## Bahrain_C2_Workplace.closing_2 = Julian day = 78
ggplot(data = filter(subdat.list, country == "Bahrain"), aes(x=julian, y=Residential)) + 
  geom_line() + 
  geom_vline(aes(xintercept=julian_lockdown, colour=restriction), 
             data = filter(country.results, country == "Bahrain"))+
  geom_text(aes(x=julian_lockdown, y=10 + 2*as.numeric(level), label=level), 
            data = filter(country.results, country == "Bahrain"))


## Belize_C1_School.closing_3 = Julian day = 80
ggplot(data = filter(subdat.list, country == "Belize"), aes(x=julian, y=residential)) + 
  geom_line() + 
  geom_vline(aes(xintercept=julian_lockdown, colour=restriction), 
             data = filter(country.results, country == "Belize"))+
  geom_text(aes(x=julian_lockdown, y=10 + 2*as.numeric(level), label=level), 
            data = filter(country.results, country == "Belize"))


## Cambodia_C2_Workplace.closing_2 = Julian day = 77
ggplot(data = filter(subdat.list, country == "Cambodia"), aes(x=julian, y=residential)) + 
  geom_line() + 
  geom_vline(aes(xintercept=julian_lockdown, colour=restriction), 
             data = filter(country.results, country == "Cambodia"))+
  geom_text(aes(x=julian_lockdown, y=10 + 2*as.numeric(level), label=level), 
            data = filter(country.results, country == "Cambodia"))


## Italy_C5_Close.public.transport_1 = Julian day = 71
ggplot(data = filter(subdat.list, country == "Italy"), aes(x=julian, y=residential)) + 
  geom_line() + 
  geom_vline(aes(xintercept=julian_lockdown, colour=restriction), 
             data = filter(country.results, country == "Italy"))+
  geom_text(aes(x=julian_lockdown, y=10 + 2*as.numeric(level), label=level), 
            data = filter(country.results, country == "Italy"))


## Indonesia_C5_Close.public.transport_1 = Julian day = 76
ggplot(data = filter(subdat.list, country == "Indonesia"), aes(x=julian, y=residential)) + 
  geom_line() + 
  geom_vline(aes(xintercept=julian_lockdown, colour=restriction), 
             data = filter(country.results, country == "Indonesia"))+
  geom_text(aes(x=julian_lockdown, y=10 + 2*as.numeric(level), label=level), 
            data = filter(country.results, country == "Indonesia"))


## Portugal_C2_Workplace.closing_2 = Julian day = 72
ggplot(data = filter(subdat.list, country == "Portugal"), aes(x=julian, y=residential)) + 
  geom_line() + 
  geom_vline(aes(xintercept=julian_lockdown, colour=restriction), 
             data = filter(country.results, country == "Portugal"))+
  geom_text(aes(x=julian_lockdown, y=10 + 2*as.numeric(level), label=level), 
            data = filter(country.results, country == "Portugal"))


## Vietnam_C2_Workplace.closing_3 = Julian day = 87
ggplot(data = filter(subdat.list, country == "Vietnam"), aes(x=julian, y=residential)) + 
  geom_line() + 
  geom_vline(aes(xintercept=julian_lockdown, colour=restriction), 
             data = filter(country.results, country == "Vietnam"))+
  geom_text(aes(x=julian_lockdown, y=10 + 2*as.numeric(level), label=level), 
            data = filter(country.results, country == "Vietnam"))


# Extract the model values for the countries that need corrected confinement dates
corrections <- tibble(country = c("Bahrain", "Belize", "Cambodia", 
                                  "Italy", "Indonesia", "Portugal",
                                  "Vietnam"), 
                      julian_lockdown = c(78, 80, 77, 71, 76, 72, 87))

# Add the ISO3 for the country names
corrections$ISO3 <- countrycode(corrections$country, origin = 'country.name', destination = 'iso3c')

library(tidyr)

# Update the corrected model values
lockdown <- bind_rows(corrections, lockdown) %>% distinct(country, .keep_all = T)

```



## Date countries cross zero

```{r}

## Join the lockdown date to the google data
google_countries <- left_join(google_countries, lockdown)


## Identify the day that a country's mobility crosses zero
## and calculate the number of days after lockdown that the 
## country's mobility crossed zero

# Nature (Parks and Beaches)
nature <- google_countries %>% group_by(country, ISO3) %>% 
            filter(julian > julian_lockdown & `Parks & Beaches` > 0) %>%
            summarise(lockdown = min(julian_lockdown),
                      parks_zero = min(julian),
                      parks_diff = parks_zero - lockdown)

# Necessities (Groceries and pharmacies)
necessities <- google_countries %>% group_by(country, ISO3) %>% 
            filter(julian > julian_lockdown & `Grocery & Pharmacy` > 0) %>%
            summarise(lockdown = min(julian_lockdown),
                      necessities_zero = min(julian),
                      necessities_diff = necessities_zero - lockdown)

# Luxuries (Retail & Recreation)
luxuries <- google_countries %>% group_by(country, ISO3) %>% 
            filter(julian > julian_lockdown & `Retail & Recreation` > 0) %>%
            summarise(lockdown = min(julian_lockdown),
                      luxuries_zero = min(julian),
                      luxuries_diff = luxuries_zero - lockdown)

# Join the dataframes
returns <- left_join(necessities, luxuries)
returns <- left_join(returns, nature)


```



## Exploring days difference 

```{r}

returns$naturediff <-  returns$parks_zero - returns$necessities_zero
returns$luxdiff <- returns$luxuries_zero - returns$necessities_zero



mean(returns$naturediff, na.rm = T) #33 days after
mean(returns$luxdiff, na.rm = T) #77


returns %>% group_by(continent) %>% 
            summarise(parks = mean(naturediff, na.rm = T),
                      lux = mean(luxdiff, na.rm = T))

```



### Plot the individual country trends with lockdown date

```{r, eval = FALSE}

# Join the lockdown dates to the full Google data for plotting
returnplots <- left_join(google_countries, returns, by = c("country", "ISO3"))

library(ggplot2)
library(ggforce)
## PLOT
ggplot(data = returnplots) + 
  geom_line(aes(x=julian, y=`Parks & Beaches`), colour = "green") + 
  geom_line(aes(x=julian, y=`Grocery & Pharmacy`), colour = "blue") + 
  geom_line(aes(x=julian, y=`Retail & Recreation`), colour = "yellow") + 
  facet_wrap_paginate(~country, ncol = 7, nrow = 7, scale="free_y", page = 1)+
  geom_vline(aes(xintercept = parks_zero), colour = "green")+
  geom_vline(aes(xintercept = necessities_zero), colour = "blue")+
  geom_vline(aes(xintercept = luxuries_zero), colour = "yellow")

ggplot(data = googleplots, aes(x=julian, y=Residential)) + 
  geom_line() + 
  facet_wrap_paginate(~country, ncol = 7, nrow = 7, scale="free_y", page = 2)+
  geom_vline(aes(xintercept = julian_lockdown), colour = "red")

ggplot(data = googleplots, aes(x=julian, y=Residential)) + 
  geom_line() + 
  facet_wrap_paginate(~country, ncol = 7, nrow = 7, scale="free_y", page = 3)+
  geom_vline(aes(xintercept = julian_lockdown), colour = "red")


```





# Add the continental info to the google data

```{r}
# Load packages
library(ggplot2);library(viridis); library(ggpubr);library(sf);library("rnaturalearth"); library("rnaturalearthdata"); library(tidyr)


# extract continent info
# These data will be used to match the world regions to the google data
world <- ne_countries(scale = "medium", returnclass = "sf")
world <- world %>% rename(ISO3 = iso_a3) 
region_un <- world$region_un
continent <- world$continent
ISO3 <- world$ISO3
continent<- tibble(ISO3, region_un, continent)


# join the regional data to the google data
google_countries <- left_join(google_countries, continent, by = "ISO3")
returns <- left_join(returns, continent, by = "ISO3")

# assign Tuvalu to Oceania
google_countries$region_un[is.na(google_countries$region_un)] <-"Oceania"
returns$region_un[is.na(returns$region_un)] <-"Oceania"

## Define "date" as a date 
google_countries$date <- as.Date(google_countries$date)

```




# Calculate the means

```{r}

mean(returns$parks_diff, na.rm = T) #101 98
mean(returns$necessities_diff, na.rm = T) #78 77
mean(returns$luxuries_diff, na.rm = T) #142 136

returns %>% group_by(continent) %>% 
            summarise(parks = mean(parks_diff, na.rm = T),
                      necessities = mean(necessities_diff, na.rm = T),
                      luxuries = mean(luxuries_diff, na.rm = T))

```



# Exploring changepoint

```{r}

cameroon <- google_countries %>% filter(country == "Cameroon")
brazil <- google_countries %>% filter(country == "Brazil")
estonia <- google_countries %>% filter(country == "Estonia" & julian < 122) 

library(changepoint)
cpt1 <- cpts(cpt.meanvar(estonia$Residential, method = "BinSeg", Q=1))

ggplot(data = estonia, aes(x=julian, y=Residential)) + 
  geom_line() + 
  geom_vline(aes(xintercept = 75), colour = "red")

```



******************
### EXPLORE THE DATE DIFFERENCES 
******************

## Download the Google mobility data

In this chunk we download the Google mobility data, reorganise it and select only the overall country trends. 

```{r, error=FALSE, warning=FALSE}

# These data were downloaded in October 2020
google <- readRDS(file = "Global_Mobility_Report.rds")

# These data were downloaded in September 2022
google <- read.csv("Global_Mobility_Report_latest.csv")

library(dplyr)
# remove the subregions and metro areas and only keep the overall country pattern
google <- google %>% filter(metro_area == "" & sub_region_1 == "")

library(naniar)
# R reads Namibia's iso2 code is as an "is.na" object, so we will rename it to NA
google$country_region_code[is.na(google$country_region_code)] <-"NA"

library(countrycode)

# Add the country codes so we ensure everything matches 
google$ISO2 <- google$country_region_code
google$ISO3 <- countrycode(google$ISO2, origin = 'iso2c', destination = 'iso3c')
google$country <- countrycode(google$ISO2, origin = 'iso2c', destination = 'country.name')

# Set the date as POSIXct
google$Date <- as.POSIXct(google$date, format='%Y-%m-%d')


# Select the specific data and rename columns
google_countries <- google %>% select(country, ISO3, Date, 
                    `Parks & Beaches`= 
                     parks_percent_change_from_baseline,
                    `Grocery & Pharmacy` = 
                     grocery_and_pharmacy_percent_change_from_baseline,
                     Residential = 
                     residential_percent_change_from_baseline,
                    `Retail & Recreation` = 
                      retail_and_recreation_percent_change_from_baseline) 

```

### Remove countries

The following 12 countries will be excluded because they do not show obvious change in lockdown dates or they do not have enough data:

"Hong Kong SAR China", "Mongolia", "South Korea", "Taiwan", "Yemen", "Liechtenstein", "RÃ©union", "North Macedonia", "Tajikistan", "Antigua & Barbuda", "Aruba", "Guinea-Bissau" 


```{r}

# Remove countries from google dataframe
google_countries <- google_countries %>% 
                     filter(!country %in% c("Hong Kong SAR China", "Mongolia", 
                                            "South Korea", "Taiwan", "Yemen", 
                                            "Liechtenstein", "RÃ©union", "North Macedonia", 
                                            "Tajikistan", "Antigua & Barbuda", "Aruba", 
                                            "Guinea-Bissau"))

```


## Find the day people were home the most

```{r}

## Less that May 1st and the greatest at home to capture the first peak
home <- google_countries %>% group_by(country, ISO3) %>% 
            filter(Date <= "2020-05-01") %>%
            filter(Residential == max(Residential, na.rm = T)) %>%
            summarise(max.home = min(Date))


## Join
google_countries <- left_join(google_countries, home)


```

## Date countries cross zero

```{r}
library(tidyverse)

## Global peak lockdown occurred on April 5th, 2020 (Bates et al., 2021)
## Julian date for peak lockdown = 96


## Identify the day that a country's mobility crosses zero
## and calculate the number of days after lockdown that the 
## country's mobility crossed zero

# Nature (Parks and Beaches)
nature <- google_countries %>% group_by(country, ISO3) %>% 
            filter(Date > max.home & `Parks & Beaches` > 0) %>%
            summarise(home =  min(max.home), # the date people were home most
                      parks_zero = min(Date), # The first date people returned to nature
                      parks_diff = parks_zero - home) # calc difference 
            

# Necessities (Groceries and pharmacies)
necessities  <- google_countries %>% group_by(country, ISO3) %>% 
            filter(Date > max.home & `Grocery & Pharmacy` > 0) %>%
            summarise(home =  min(max.home), # the date people were home most
                      necessities_zero = min(Date), # The first date people returned to nature
                      necessities_diff = necessities_zero - home) # calc difference 


# Luxuries (Retail & Recreation)
luxuries <- google_countries %>% group_by(country, ISO3) %>% 
            filter(Date > max.home & `Retail & Recreation` > 0) %>%
            summarise(home =  min(max.home), # the date people were home most
                      luxuries_zero = min(Date), # The first date people returned to nature
                      luxuries_diff = luxuries_zero - home) # calc difference 

# Join the dataframes
returns <- left_join(necessities, luxuries)
returns <- left_join(returns, nature)


# Calculate the differences in days
returns$naturediff <-  as.numeric(returns$parks_zero - returns$necessities_zero, units = "days")
returns$luxdiff <- as.numeric(returns$luxuries_zero - returns$necessities_zero, units = "days")


# Median global values
median(returns$naturediff, na.rm = T) # 13 days after necessities
median(returns$luxdiff, na.rm = T) # 78 after necessities


# Global median for return dates
median(returns$necessities_diff, na.rm = T) # 48 days after necessities
median(returns$parks_diff, na.rm = T) # 78 after necessities
median(returns$luxuries_diff, na.rm = T) # 153 after necessities

```


# Continental differences

```{r}

# Load packages
library(ggplot2);library(viridis); library(ggpubr);library(sf);library("rnaturalearth"); library("rnaturalearthdata"); library(tidyr)


# extract continent info
# These data will be used to match the world regions to the google data
world <- ne_countries(scale = "medium", returnclass = "sf")
world <- world %>% rename(ISO3 = iso_a3) 
region_un <- world$region_un
continent <- world$continent
subregion <- world$subregion
ISO3 <- world$ISO3
continent<- tibble(ISO3, region_un, continent, subregion)


# join the regional data to the google data
returns <- left_join(returns, continent, by = "ISO3")

# assign Tuvalu to Oceania
returns$region_un[is.na(returns$region_un)] <-"Oceania"


```


## Create World Map Plot

```{r}

#Get world map info
world_map <- map_data("world") %>%  
              group_by(region) %>% 
              summarise(long=mean(long),
                        lat=mean(lat)) %>%
              rename(country = region)

# Join the data
returns <- left_join(returns, world_map)


## Summarise the subregion/continental differences
regions <- returns %>% group_by(subregion) %>% 
            summarise(parks = median(naturediff, na.rm = T),
                      parks.min = min(naturediff, na.rm = T),
                      parks.max = max(naturediff, na.rm = T),
                      lux = median(luxdiff, na.rm = T),
                      lux.min = min(luxdiff, na.rm = T),
                      lux.max = max(luxdiff, na.rm = T),
                      nature = median(parks_diff, na.rm = T),
                      necessities = median(necessities_diff, na.rm = T),
                      luxuries = median(luxuries_diff, na.rm = T),
                      long=mean(long, na.rm = T),
                      lat=mean(lat, na.rm = T),
                      countries = n()) %>%
            arrange(parks)

# Save
write.csv(regions, "regions.csv")

## Colour countries that we have used
# Set colors
world <- mutate(world, fill = ifelse(ISO3 %in% returns$ISO3, 
                                     "Monitored", "Non-monitored"))


## Set the map theme
maptheme <-  theme_bw(base_size = 15)+
  theme(axis.title.y = element_blank(), 
        axis.title.x = element_blank(),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        legend.title = element_blank(),
        legend.position="none",
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())


library(ggrepel)

# World map with dots for locations
map.plot<- ggplot() +
    geom_sf(data = world, fill = "snow3", colour = "snow3", size = 0.2) +
     maptheme+
    geom_sf(data = world, aes(fill = fill), colour = "cornsilk", size = 0.01) +
    scale_fill_manual(values = c("cornsilk", "snow3"))+
    geom_point(data = regions, 
               aes(x = long, y = lat),
               shape=21)+
    coord_sf(xlim = c(-180, 220), ylim = c(-65, 120), expand = FALSE)



# Save the plot
ggsave("map plot.pdf", 
       width = 180, height = 150, unit = "mm")

```

## Bar plots of regional trends

```{r}

# Gather the data for plotting
map.regions <- regions %>% 
            select(subregion, countries, 
                   parks, lux, 
                   long, lat)  %>%
            gather(Mobility, Difference, parks, lux)

# define for plotting
map.regions2$mob <- "mob"

# define for plotting
map.regions$Mobility <- factor(map.regions$Mobility, levels = c("parks", "lux"))

## Set plot theme
plot.theme <-  theme_void()+
  theme(legend.title = element_blank(),
        legend.position="none")

 
# Plot
ggplot(data = map.regions,
       aes(x = mob, y = Difference, fill = Mobility)) +
    scale_fill_manual(values = c("#21908CFF","#FDE725FF"))+
    geom_bar(stat= "identity",width = 0.3, position = position_dodge(0.35))+
    geom_hline(yintercept = 0, size = 0.1)+
    facet_wrap(~subregion, strip.position = "bottom")+
    plot.theme


## plot the number of day after peak lockdown
map.regions2 <- regions %>% 
            select(subregion, countries, 
                   nature, luxuries, necessities, 
                   long, lat)  %>%
            gather(Mobility, Difference, nature:necessities)

library(stringr)
map.regions2$subregion2 <-str_wrap(map.regions2$subregion, 20)


library(viridis)

bars <- ggplot(data = map.regions2,
       aes(x = mob, y = Difference, fill = Mobility)) +
     scale_fill_viridis(discrete = TRUE, direction = -1)+
    #scale_fill_manual(values = c("#C15CCB","#00868B", "#FF6A00"))+
    geom_bar(stat= "identity",width = 0.3, position = position_dodge(0.35))+
    #geom_hline(yintercept = 0, size = 0.1)+
    facet_wrap(~subregion2, strip.position = "bottom")+
    plot.theme


# Save the plot
ggsave("bars plot.pdf", 
       width = 150, height = 90, unit = "mm")
```



## Global plot for time at parks, pharmacies and luxuries

Here we calculate and plot the global median change of time at parks, pharmacies and luxuries after lockdown.


```{r}
library(dplyr); library(tidyr)

## Calculate global median movement at parks, pharmacies and residential
google_median <- google_countries %>% group_by(Date) %>% 
      summarise(`Parks & Beaches`= median(`Parks & Beaches`, na.rm = TRUE),
                `Grocery & Pharmacy` = median(`Grocery & Pharmacy`, na.rm = TRUE),
                `Retail & Recreation` = median(`Retail & Recreation`, na.rm = TRUE))


## Rearrange for plotting
google_median <- google_median %>% gather(type, change, `Parks & Beaches`:`Retail & Recreation`)

## Define plot theme
global_plottheme <- theme_bw(base_size = 15)+ # set the background theme       
  theme(panel.grid.major = element_blank(), # remove the major lines
        panel.grid.minor = element_blank(), # remove the minor lines
        axis.title.x = element_blank(),
        strip.text.x = element_text(size = 15, color = "white"), 
        strip.background = element_rect(fill="black"),
        legend.title = element_blank(),
        legend.position="none")


## Create global plot
timeplot<- ggplot(google_median, aes(Date, change)) +
  geom_line( aes(colour = type))+
  geom_hline(yintercept = 0, linetype = "dashed")+
  labs(y = "Change in length \n of visit (%)")+
  #scale_colour_manual(values = c( "#C15CCB","#00868B", "#FF6A00"))+
  scale_colour_viridis(discrete = TRUE)+
  global_plottheme


# Save the plot
ggsave("time plot.pdf", 
       width = 180, height = 75, unit = "mm")

```


## Combine the plots 

```{r}

library(patchwork)

map.plot / timeplot + plot_layout(height=c(2,1))

# Install ggview
remotes::install_github("idmn/ggview")
library(ggview)
ggview(units = "mm", width = 150, height = 90)
```





## EXPLORING PATTERNS PLOTS


### Plot the individual country trends with lockdown date

```{r, eval = FALSE}

# Join the lockdown dates to the full Google data for plotting
googleplots <- left_join(googlestart, chosen_start, by = c("country", "ISO3"))

library(ggplot2)
library(ggforce)
## PLOT
ggplot(data = googleplots, aes(x=julian, y=Residential)) + 
  geom_line() + 
  facet_wrap_paginate(~country, ncol = 7, nrow = 7, scale="free_y", page = 1)+
  geom_vline(aes(xintercept = julian_lockdown), colour = "red")

ggplot(data = googleplots, aes(x=julian, y=Residential)) + 
  geom_line() + 
  facet_wrap_paginate(~country, ncol = 7, nrow = 7, scale="free_y", page = 2)+
  geom_vline(aes(xintercept = julian_lockdown), colour = "red")



ggplot(data = google_countries, aes(x=julian, y=Residential)) + 
  geom_line() + 
  facet_wrap_paginate(~country, ncol = 7, nrow = 7, scale="free_y", page = 2)
  



```



## Exploring trends

```{r}

# Join the lockdown dates to the full Google data for plotting
returnplots <- left_join(google_countries, returns, by = c("country", "ISO3"))

## NESSESITIES
ggplot(data = returnplots, aes(x=Date, y=`Grocery & Pharmacy`)) + 
  geom_line() + 
  facet_wrap_paginate(~country, ncol = 7, nrow = 7, scale="free_y", page = 3)+
  geom_hline(aes(yintercept = 0), linetype = "dashed")+
  geom_vline(aes(xintercept = max.home), colour = "red")+
  geom_vline(aes(xintercept = necessities_zero), colour = "blue")
  

## NATURE
ggplot(data = returnplots, aes(x=date, y=`Parks & Beaches`)) + 
  geom_line() + 
  facet_wrap_paginate(~country, ncol = 7, nrow = 7, scale="free_y", page = 1)+
  geom_hline(aes(yintercept = 0), linetype = "dashed")+
  geom_vline(aes(xintercept = max.home), colour = "red")+
  geom_vline(aes(xintercept = parks_zero), colour = "blue")


returnplots$date <- as.Date(returnplots$date)
ggplot(data = (filter(returnplots, country == "Canada")), aes(x=date, y=`Parks & Beaches`)) + 
  geom_line() 


## LUXURIES
ggplot(data = returnplots, aes(x=id, y=`Retail & Recreation`)) + 
  geom_line() + 
  facet_wrap_paginate(~country, ncol = 7, nrow = 7, scale="free_y", page = 1)+
  geom_hline(aes(yintercept = 0), linetype = "dashed")+
  geom_vline(aes(xintercept = max.home), colour = "red")+
  geom_vline(aes(xintercept = luxuries_zero), colour = "blue")

```



### Plot the individual country trends with lockdown date

```{r, eval = FALSE}

# Join the lockdown dates to the full Google data for plotting
returnplots <- left_join(google_countries, returns, by = c("country", "ISO3"))

library(ggplot2)
library(ggforce)
## PLOT
ggplot(data = returnplots) + 
  geom_line(aes(x=julian, y=`Parks & Beaches`), colour = "green") + 
  geom_line(aes(x=julian, y=`Grocery & Pharmacy`), colour = "blue") + 
  geom_line(aes(x=julian, y=`Retail & Recreation`), colour = "yellow") + 
  facet_wrap_paginate(~country, ncol = 7, nrow = 7, scale="free_y", page = 1)+
  geom_vline(aes(xintercept = parks_zero), colour = "green")+
  geom_vline(aes(xintercept = necessities_zero), colour = "blue")+
  geom_vline(aes(xintercept = luxuries_zero), colour = "yellow")

ggplot(data = googleplots, aes(x=julian, y=Residential)) + 
  geom_line() + 
  facet_wrap_paginate(~country, ncol = 7, nrow = 7, scale="free_y", page = 2)+
  geom_vline(aes(xintercept = julian_lockdown), colour = "red")

ggplot(data = googleplots, aes(x=julian, y=Residential)) + 
  geom_line() + 
  facet_wrap_paginate(~country, ncol = 7, nrow = 7, scale="free_y", page = 3)+
  geom_vline(aes(xintercept = julian_lockdown), colour = "red")


```



# Exploring countries difference

```{r}
# Join the lockdown dates to the full Google data for plotting
returnplots <- left_join(google_countries, returns, by = c("country", "ISO3"))


ggplot(data = filter(returnplots, continent == "South America"),
       aes(x=Date, y=`Parks & Beaches`)) + 
  geom_line() + 
  facet_wrap(~country, scale="free_y")+
  geom_hline(aes(yintercept = 0), linetype = "dashed")+
  geom_vline(aes(xintercept = max.home), colour = "red")+
  geom_vline(aes(xintercept = parks_zero), colour = "blue")



ggplot(data = filter(returnplots, continent == "Africa"),
       aes(x=Date, y=`Grocery & Pharmacy`)) + 
  geom_line() + 
  facet_wrap(~country, scale="free_y")+
  geom_hline(aes(yintercept = 0), linetype = "dashed")+
  geom_vline(aes(xintercept = max.home), colour = "red")+
  geom_vline(aes(xintercept = necessities_zero), colour = "blue")




ggplot(data = filter(returnplots, continent == "Oceania"),
       aes(x=Date, y=`Retail & Recreation`)) + 
  geom_line() + 
  facet_wrap(~country, scale="free_y")+
  geom_hline(aes(yintercept = 0), linetype = "dashed")+
  geom_vline(aes(xintercept = max.home), colour = "red")+
  geom_vline(aes(xintercept = luxuries_zero), colour = "blue")

```

# Mean trends per region

```{r}

returnsubplots <- returnplots %>% group_by(continent, Date) %>% 
                                  summarise(`Parks & Beaches`= median(`Parks & Beaches`),
                                            `Grocery & Pharmacy`= median(`Grocery & Pharmacy`),
                                            `Retail & Recreation`= median(`Retail & Recreation`),
                                            necessities = median(necessities_zero),
                                            nature = median(parks_zero),
                                            luxuries = median(luxuries_zero))




## Rearrange for plotting
returnsubplots2 <- returnsubplots %>% gather(type, change, `Parks & Beaches`:`Retail & Recreation`)

## Define plot theme
global_plottheme <- theme_bw(base_size = 15)+ # set the background theme       
  theme(panel.grid.major = element_blank(), # remove the major lines
        panel.grid.minor = element_blank(), # remove the minor lines
        axis.title.x = element_blank(),
        strip.text.x = element_text(size = 15, color = "white"), 
        strip.background = element_rect(fill="black"))


## Create global plot
ggplot(returnsubplots2, aes(Date, change)) +
  geom_line(data = returnsubplots2, aes(group = continent, colour = continent))+
  #geom_line(size = 1)+
 # geom_vline(xintercept = as.numeric(as.Date("2020-07-28")), 
#             linetype = "dashed", colour = "red", size = 1)+
  geom_hline(yintercept = 0, linetype = "dashed")+
  #scale_x_date(date_breaks = "8 week", date_labels = "%b %d")+
  facet_wrap(~type, scales = "free", nrow = 3)+
  labs(y = "Change in length of visit (%)")+
  global_plottheme

```



# Visualising

```{r}
## Set plot theme
plot.theme <-  theme_bw(base_size = 15)+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
  theme(axis.title.y = element_text(vjust = 3)) +
  theme(axis.title.x = element_text(vjust = -1))+
  theme(strip.text.x = element_text(size = 16, color = "white", face = "bold"), 
        strip.background = element_rect(fill="black"),
        legend.title = element_blank(),
        legend.position="none")


## NATURE PLOT
# Rearrange the regions for plotting
regions <- regions %>% arrange(desc(parks))%>%
  mutate(subregion=factor(subregion, levels=subregion))

# Set colour
regions <- regions %>% mutate(Colour = ifelse(parks < 0, "#01579B","#B71C1C"))

# Plot
ggplot(data = regions,
       aes(x = subregion, y = parks, fill = Colour)) + 
    geom_col()+
    plot.theme+
    geom_hline(yintercept = 0)+
    scale_fill_identity(guide = FALSE)+
    labs(x = "Geographic Region", y = 'Number of Days (Median)')+
   coord_flip()+
  theme(axis.title.y = element_blank())+
  ggtitle("Number of days taken to return to nature \n after people returned to necessities")



## LUXURIES
# Rearrange the regions for plotting
regions <- regions %>% arrange(desc(lux))%>%
  mutate(subregion=factor(subregion, levels=subregion))

# Set colour
regions <- regions %>% mutate(Colour = ifelse(lux < 0, "#01579B","#B71C1C"))

# Plot
ggplot(data = regions,
       aes(x = subregion, y = lux, fill = Colour)) + 
    geom_col()+
    plot.theme+
    geom_hline(yintercept = 0)+
    scale_fill_identity(guide = FALSE)+
    labs(x = "Geographic Region", y = 'Number of Days (Median)')+
   coord_flip()+
  theme(axis.title.y = element_blank())+
  ggtitle("Number of days taken to return to luxuries \n after people returned to necessities")



```

